package com.example.grabitTest

import android.Manifest
import android.content.Intent
import android.content.pm.PackageManager
import android.graphics.Bitmap
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.tts.TextToSpeech
import android.util.Log
import android.view.View
import android.widget.AdapterView
import android.widget.ArrayAdapter
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import android.graphics.RectF
import com.example.grabitTest.databinding.ActivityMainBinding
import com.google.mediapipe.framework.image.BitmapImageBuilder
import com.google.mediapipe.tasks.core.BaseOptions
import com.google.mediapipe.tasks.vision.core.RunningMode
import com.google.mediapipe.tasks.vision.handlandmarker.HandLandmarker
import com.google.mediapipe.tasks.vision.handlandmarker.HandLandmarkerResult
import com.google.mediapipe.tasks.components.containers.NormalizedLandmark
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.gpu.GpuDelegate
import java.io.BufferedReader
import java.io.InputStreamReader
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel
import android.os.Handler
import android.os.Looper
import java.util.concurrent.ExecutorService
import java.util.concurrent.Executors
import java.util.concurrent.atomic.AtomicReference
import kotlin.math.exp
import kotlin.math.max
import kotlin.math.min
import kotlin.math.sqrt

class MainActivity : AppCompatActivity() {

    private lateinit var binding: ActivityMainBinding
    private lateinit var cameraExecutor: ExecutorService

    // AI ëª¨ë¸
    private var yoloxInterpreter: Interpreter? = null
    private var gpuDelegate: GpuDelegate? = null
    private var handLandmarker: HandLandmarker? = null

    // LIVE_STREAM: Hands ê²°ê³¼ëŠ” ì½œë°±ìœ¼ë¡œ ì˜´ â†’ ìµœì‹  ê°’ë§Œ ë³´ê´€
    private val latestHandsResult = AtomicReference<HandLandmarkerResult?>(null)

    // FPS ì¸¡ì •
    private var frameCount = 0
    private var lastFpsTime = System.currentTimeMillis()

    private var lastYoloxMaxConf = 0f

    /** í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ ì´ë¦„ (assets/classes.txt, í•œ ì¤„ì— í•˜ë‚˜, # ë¬´ì‹œ) */
    private var classLabels: List<String> = emptyList()

    enum class SearchState { SEARCHING, LOCKED }
    private var searchState = SearchState.SEARCHING
    private var frozenBox: OverlayView.DetectionBox? = null
    private var frozenImageWidth = 0
    private var frozenImageHeight = 0
    /** State Bì—ì„œ ê³„ì† ì¶”ì í•  íƒ€ê²Ÿ ë¼ë²¨ (ë½ ì‹œì ì˜ box.label) */
    private var lockedTargetLabel: String = ""

    /** ê°™ì€ ê°ì²´ê°€ ì—°ì† Ní”„ë ˆì„ ê°ì§€ëì„ ë•Œ ê³ ì • */
    private val LOCK_CONFIRM_FRAMES = 2
    private var pendingLockBox: OverlayView.DetectionBox? = null
    private var pendingLockCount = 0

    /** LOCKED ì‹œ YOLOX ê²€ì¦+ë³´ì •: Ní”„ë ˆì„ë§ˆë‹¤ 1íšŒ ì‹¤í–‰ (3ìœ¼ë¡œ ì¤„ì—¬ ë“œë¦¬í”„íŠ¸ ë³´ì • ë¹ˆë„ ì¦ê°€) */
    private val VALIDATION_INTERVAL = 3
    private val VALIDATION_FAIL_LIMIT = 3
    private var validationFailCount = 0
    private var lockedFrameCount = 0

    private lateinit var gyroManager: GyroTrackingManager
    private val opticalFlowTracker = OpticalFlowTracker()

    private var wasOccluded = false  // occlusion â†’ non-occlusion ì „í™˜ ì‹œ gyro ë™ê¸°í™”ìš©

    private val TARGET_CONFIDENCE_THRESHOLD = 0.5f  // 50% ì´ìƒ í™•ì‹  ì‹œ ê³ ì • (íƒì§€ ìš©ì´í•˜ê²Œ ì™„í™”)
    private val TARGET_ANY = "ëª¨ë“  ìƒí’ˆ"
    private val currentTargetLabel = AtomicReference<String>("")

    // STT / TTS
    private var sttManager: STTManager? = null
    private var ttsManager: TTSManager? = null
    private var beepPlayer: BeepPlayer? = null
    private var voiceFlowController: VoiceFlowController? = null
    private val searchTimeoutHandler = Handler(Looper.getMainLooper())
    private var searchTimeoutRunnable: Runnable? = null
    private val SEARCH_TIMEOUT_MS = 30_000L
    private val POSITION_ANNOUNCE_INTERVAL_MS = 5000L
    private var positionAnnounceRunnable: Runnable? = null
    /** ìŒì„±ìœ¼ë¡œ ì°¾ê¸° ìš”ì²­í•œ ìƒí’ˆ í´ë˜ìŠ¤(ì‹¤ì œ ì¼ì¹˜ ì—¬ë¶€ ê²€ì‚¬ìš©). null = ìŒì„± í”Œë¡œìš° ì•„ë‹˜ */
    private var voiceSearchTargetLabel: String? = null

    private val REQUIRED_PERMISSIONS = arrayOf(
        Manifest.permission.CAMERA,
        Manifest.permission.RECORD_AUDIO
    )
    private val REQUEST_CODE_PERMISSIONS = 10

    // í™”ë©´ ìƒíƒœ
    enum class ScreenState { FIRST_SCREEN, CAMERA_SCREEN }
    private var screenState = ScreenState.FIRST_SCREEN

    // TTS / STT
    private var tts: TextToSpeech? = null
    private var speechRecognizer: SpeechRecognizer? = null
    private var ttsDetectedPlayed = false   // ê°ì²´ íƒì§€ TTS 1íšŒë§Œ
    private var ttsGrabPlayed = false      // ì† ë»—ì–´ ì¡ìœ¼ì„¸ìš” TTS (LOCKED í›„)
    private var ttsGrabbedPlayed = false   // ê°ì²´ ì¡ì•˜ìŒ TTS 1íšŒë§Œ
    private var ttsAskAnotherPlayed = false
    private var waitingForYesNo = false    // ì˜ˆ/ì•„ë‹ˆì˜¤ STT ëŒ€ê¸° ì¤‘
    private var handsOverlapFrameCount = 0  // ì†-ë°•ìŠ¤ ê²¹ì¹¨ ì—°ì† í”„ë ˆì„ ìˆ˜ (ì˜ëª»ëœ ì¡ê¸° íŒì •ìš©)
    private var pinchGrabFrameCount = 0     // ì—„ì§€+ê²€ì§€ ì¡ê¸° íŒì • ì—°ì† í”„ë ˆì„

    // ì† ìœ„ì¹˜ ì•ˆë‚´ TTS (ì†ì„ ë” ë»—ì–´ì£¼ì„¸ìš” ë“±)
    private val handGuidanceHandler = Handler(Looper.getMainLooper())
    private var handGuidanceRunnable: Runnable? = null
    private var lastHandGuidanceTimeMs = 0L
    private val HAND_GUIDANCE_INTERVAL_MS = 5000L

    /** LOCKED ì‹œ ë§ˆì§€ë§‰ìœ¼ë¡œ YOLOX ê²€ì¦ ì„±ê³µí•œ ì‹œê°. ë°•ìŠ¤ë¥¼ ìƒì€ ë’¤ 2ì´ˆ ì§€ë‚˜ë©´ ì¶”ë¡ ì„ ë§¤ í”„ë ˆì„ ì¼œì„œ ì¬íƒì§€ */
    private var lastSuccessfulValidationTimeMs = 0L
    private val REACQUIRE_INFERENCE_AFTER_MS = 2000L

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        binding = ActivityMainBinding.inflate(layoutInflater)
        setContentView(binding.root)

        cameraExecutor = Executors.newSingleThreadExecutor()

        loadClassLabels()
        ProductDictionary.load(this)
        initYOLOX()
        initMediaPipeHands()
        setupTargetSpinner()
        initGyroTrackingManager()
        initSttTts()

        binding.firstScreen.setOnClickListener { onFirstScreenClicked() }
        binding.resetBtn.setOnClickListener { gyroManager.resetToSearchingFromUI() }
        binding.btnFirstScreen.setOnClickListener { goToFirstScreen() }
        setupProductDrawer()
        binding.micButton.setOnClickListener { onMicButtonClicked() }
        binding.confirmBtn.setOnClickListener { voiceFlowController?.onConfirmClicked() }
        binding.reinputBtn.setOnClickListener { voiceFlowController?.onReinputClicked() }
        binding.retryBtn.setOnClickListener { voiceFlowController?.onRetrySearch() }

        if (allPermissionsGranted()) {
            showFirstScreen()
            // TTSëŠ” initTTS ì½œë°±ì—ì„œ ì¤€ë¹„ë˜ë©´ playWelcomeTTS() í˜¸ì¶œ (ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€)
        } else {
            ActivityCompat.requestPermissions(
                this, REQUIRED_PERMISSIONS, REQUEST_CODE_PERMISSIONS
            )
        }
    }

    private fun initTTS() {
        tts = TextToSpeech(this) { status ->
            if (status == TextToSpeech.SUCCESS) {
                tts?.language = java.util.Locale.KOREAN
                runOnUiThread {
                    if (allPermissionsGranted()) playWelcomeTTS()
                }
            }
        }
    }

    private fun initSTT() {
        if (SpeechRecognizer.isRecognitionAvailable(this)) {
            speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)
        }
    }

    /** í–„ë²„ê±° ë©”ë‰´ - ì°¾ì„ ìˆ˜ ìˆëŠ” í’ˆëª© ë¦¬ìŠ¤íŠ¸ Drawer */
    private fun setupProductDrawer() {
        val productList = listOf(TARGET_ANY) + classLabels
        binding.productListView.adapter = ArrayAdapter(this, R.layout.item_product, R.id.itemProductName, productList)
        binding.productListView.setOnItemClickListener { _, _, position, _ ->
            val label = productList.getOrNull(position) ?: return@setOnItemClickListener
            currentTargetLabel.set(label)
            binding.drawerLayout.closeDrawers()
            if (screenState == ScreenState.FIRST_SCREEN) {
                val displayName = if (ProductDictionary.isLoaded()) ProductDictionary.getDisplayNameKo(label) else label
                speak("$displayName ì°¾ê² ìŠµë‹ˆë‹¤.") {
                    runOnUiThread { showCameraScreen() }
                }
            } else {
                binding.statusText.text = "ì°¾ëŠ” ì¤‘: $label"
                transitionToSearching()
            }
        }
        binding.menuButton.setOnClickListener {
            binding.drawerLayout.openDrawer(binding.drawerContent)
        }
    }

    private fun speak(text: String, onDone: (() -> Unit)? = null) {
        tts?.speak(text, TextToSpeech.QUEUE_FLUSH, null, null)
        onDone?.let { cb ->
            binding.root.postDelayed({ runOnUiThread(cb) }, (text.length * 80L).coerceIn(1500L, 4000L))
        }
    }

    private fun playWelcomeTTS() {
        speak("ê·¸ë©ITì…ë‹ˆë‹¤. ì›í•˜ì‹œëŠ” ìƒí’ˆì„ ë§ì”€í•´ ì£¼ì„¸ìš”.")
    }

    private fun showFirstScreen() {
        screenState = ScreenState.FIRST_SCREEN
        binding.firstScreen.visibility = View.VISIBLE
        binding.cameraContainer.visibility = View.GONE
        binding.btnFirstScreen.visibility = View.GONE
        binding.targetRow.visibility = View.GONE
        binding.statusText.text = ""
        stopHandGuidanceTTS()
    }

    /** ìš°ì¸¡ í•˜ë‹¨ 'ì²« í™”ë©´' ë²„íŠ¼: ì¹´ë©”ë¼ ë„ê³  ì²« í™”ë©´ìœ¼ë¡œ */
    private fun goToFirstScreen() {
        transitionToSearching()
        stopCamera()
        speak("ì²« í™”ë©´ìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.") {
            runOnUiThread {
                showFirstScreen()
                playWelcomeTTS()
            }
        }
    }

    private fun showCameraScreen() {
        screenState = ScreenState.CAMERA_SCREEN
        binding.firstScreen.visibility = View.GONE
        binding.cameraContainer.visibility = View.VISIBLE
        binding.btnFirstScreen.visibility = View.VISIBLE
        binding.overlayView.visibility = View.VISIBLE
        binding.statusText.text = "ì°¾ëŠ” ì¤‘: ${getTargetLabel()}"
        startCamera()
    }

    private fun onFirstScreenClicked() {
        if (screenState != ScreenState.FIRST_SCREEN) return
        sttManager?.startListening()
    }

    private fun initSttTts() {
        ttsManager = TTSManager(
            context = this,
            onReady = { Log.d(TAG, "TTS ì¤€ë¹„ ì™„ë£Œ") },
            onSpeakDone = { },
            onError = { msg ->
                runOnUiThread {
                    Log.e(TAG, "[TTS ì—ëŸ¬] $msg")
                    Toast.makeText(this, msg, Toast.LENGTH_SHORT).show()
                }
            }
        )
        beepPlayer = BeepPlayer().also { it.init() }

        ttsManager?.init { success ->
            runOnUiThread {
                if (success && beepPlayer != null) {
                    voiceFlowController = VoiceFlowController(
                        ttsManager = ttsManager!!,
                        beepPlayer = beepPlayer!!,
                        onStateChanged = { _, _ -> runOnUiThread { updateVoiceFlowButtonVisibility() } },
                        onSystemAnnounce = { msg -> runOnUiThread { binding.sttResultText.text = "ğŸ”Š $msg" } },
                        onRequestStartStt = { runOnUiThread { sttManager?.startListening() } },
                        onStartSearch = { productName -> runOnUiThread { onStartSearchFromVoiceFlow(productName) } }
                    )
                    voiceFlowController?.start()
                    Log.d(TAG, "VoiceFlowController ì‹œì‘")
                } else {
                    Log.e(TAG, "TTS ì´ˆê¸°í™” ì‹¤íŒ¨")
                }
            }
        }

        sttManager = STTManager(
            context = this,
            onResult = { text ->
                runOnUiThread {
                    Log.d(TAG, "[STT ê²°ê³¼] $text")
                    binding.sttResultText.text = "ğŸ¤ $text"
                    voiceFlowController?.onSttResult(text)
                }
            },
            onError = { msg ->
                runOnUiThread {
                    Log.e(TAG, "[STT ì—ëŸ¬] $msg")
                    binding.sttResultText.text = "âŒ $msg"
                    Toast.makeText(this, msg, Toast.LENGTH_SHORT).show()
                }
            },
            onListeningChanged = { listening ->
                runOnUiThread {
                    binding.micButton.isEnabled = !listening
                    if (listening) binding.sttResultText.text = "ğŸ¤ ë“£ëŠ” ì¤‘..."
                    updateVoiceFlowButtonVisibility()
                }
            }
        ).also { if (it.init()) Log.d(TAG, "STT ì´ˆê¸°í™” ì™„ë£Œ") }
    }

    private fun updateVoiceFlowButtonVisibility() {
        val state = voiceFlowController?.currentState ?: return
        when (state) {
            VoiceFlowController.VoiceFlowState.CONFIRM_PRODUCT,
            VoiceFlowController.VoiceFlowState.WAITING_CONFIRMATION -> {
                binding.confirmBtn.visibility = View.VISIBLE
                binding.reinputBtn.visibility = View.VISIBLE
                binding.retryBtn.visibility = View.GONE
            }
            VoiceFlowController.VoiceFlowState.SEARCH_RESULT -> {
                binding.confirmBtn.visibility = View.GONE
                binding.reinputBtn.visibility = View.GONE
                binding.retryBtn.visibility = View.VISIBLE
            }
            VoiceFlowController.VoiceFlowState.SEARCH_FAILED -> {
                binding.confirmBtn.visibility = View.GONE
                binding.reinputBtn.visibility = View.GONE
                binding.retryBtn.visibility = View.VISIBLE
                binding.previewView.visibility = View.GONE
                binding.overlayView.visibility = View.GONE
            }
            VoiceFlowController.VoiceFlowState.WAITING_PRODUCT_NAME,
            VoiceFlowController.VoiceFlowState.APP_START -> {
                binding.confirmBtn.visibility = View.GONE
                binding.reinputBtn.visibility = View.GONE
                binding.retryBtn.visibility = View.GONE
                // preview/overlayëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ (ë²„íŠ¼ìœ¼ë¡œ ì¹´ë©”ë¼ ì¼  ë’¤ STT ì½œë°± ì‹œ êº¼ì§€ë˜ í˜„ìƒ ë°©ì§€)
            }
            else -> {
                binding.confirmBtn.visibility = View.GONE
                binding.reinputBtn.visibility = View.GONE
                binding.retryBtn.visibility = View.GONE
            }
        }
    }

    /** ìŒì„± í”Œë¡œìš°ì—ì„œ í™•ì¸ í´ë¦­ ì‹œ: ì¹´ë©”ë¼ ì¼œê³  ì‹¤ì œ íƒì§€ ì‹œì‘ */
    private fun onStartSearchFromVoiceFlow(productName: String) {
        cancelSearchTimeout()
        val targetClass = mapSpokenToClass(productName)
        voiceSearchTargetLabel = targetClass
        currentTargetLabel.set(targetClass)
        binding.targetSpinner.setSelection(
            (listOf(TARGET_ANY) + classLabels).indexOf(targetClass).coerceAtLeast(0)
        )
        binding.startSearchBtn.visibility = View.GONE
        binding.previewView.visibility = View.VISIBLE
        binding.overlayView.visibility = View.VISIBLE
        startCamera()
        startSearchTimeout()
    }

    private fun mapSpokenToClass(spoken: String): String {
        if (spoken.isBlank()) return TARGET_ANY
        ProductDictionary.findClassByStt(spoken)?.let { return it }
        val s = spoken.trim().lowercase().replace(" ", "")
        for (label in classLabels) {
            val labelNorm = label.lowercase().replace("_", "")
            if (labelNorm.contains(s) || s.contains(labelNorm.take(3))) return label
        }
        return TARGET_ANY
    }

    private fun stopCamera() {
        try {
            ProcessCameraProvider.getInstance(this).get().unbindAll()
        } catch (_: Exception) {}
    }

    private fun startSearchTimeout() {
        cancelSearchTimeout()
        searchTimeoutRunnable = Runnable {
            if (voiceFlowController?.currentState == VoiceFlowController.VoiceFlowState.SEARCHING_PRODUCT) {
                runOnUiThread {
                    voiceSearchTargetLabel = null
                    voiceFlowController?.onSearchComplete(false)
                    binding.previewView.visibility = View.GONE
                    binding.overlayView.visibility = View.GONE
                }
            }
        }
        searchTimeoutHandler.postDelayed(searchTimeoutRunnable!!, SEARCH_TIMEOUT_MS)
    }

    private fun cancelSearchTimeout() {
        searchTimeoutRunnable?.let { searchTimeoutHandler.removeCallbacks(it) }
        searchTimeoutRunnable = null
    }

    private fun startPositionAnnounce() {
        stopPositionAnnounce()
        positionAnnounceRunnable = object : Runnable {
            override fun run() {
                val box = frozenBox ?: return
                val w = frozenImageWidth
                val h = frozenImageHeight
                if (w <= 0 || h <= 0) return
                val displayName = if (ProductDictionary.isLoaded())
                    ProductDictionary.getDisplayNameKo(lockedTargetLabel) else lockedTargetLabel
                voiceFlowController?.announcePosition(displayName, box.rect, w, h)
                searchTimeoutHandler.postDelayed(this, POSITION_ANNOUNCE_INTERVAL_MS)
            }
        }
        searchTimeoutHandler.postDelayed(positionAnnounceRunnable!!, POSITION_ANNOUNCE_INTERVAL_MS)
    }

    private fun stopPositionAnnounce() {
        positionAnnounceRunnable?.let { searchTimeoutHandler.removeCallbacks(it) }
        positionAnnounceRunnable = null
    }

    private fun onMicButtonClicked() {
        if (!allPermissionsGranted()) {
            Toast.makeText(this, "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
            ActivityCompat.requestPermissions(this, REQUIRED_PERMISSIONS, REQUEST_CODE_PERMISSIONS)
            return
        }
        if (sttManager?.isListening() == true) {
            sttManager?.stopListening()
        } else {
            binding.sttResultText.text = "ğŸ¤ ë“£ëŠ” ì¤‘..."
            sttManager?.startListening()
        }
    }

    private fun initGyroTrackingManager() {
        gyroManager = GyroTrackingManager(
            context = this,
            onBoxUpdate = { update: BoxUpdate ->
                runOnUiThread {
                    val box = OverlayView.DetectionBox(
                        label = lockedTargetLabel,
                        confidence = 0.9f,
                        rect = update.rect,
                        topLabels = listOf(lockedTargetLabel to 90),
                        rotationDegrees = update.rotationDegrees
                    )
                    frozenBox = box
                    binding.overlayView.setDetections(listOf(box), frozenImageWidth, frozenImageHeight)
                }
            },
            onTrackingLost = { transitionToSearching() }
        )
    }

    private fun initMediaPipeHands() {
        try {
            val baseOptions = BaseOptions.builder()
                .setModelAssetPath("hand_landmarker.task")
                .build()

            val options = HandLandmarker.HandLandmarkerOptions.builder()
                .setBaseOptions(baseOptions)
                .setRunningMode(RunningMode.LIVE_STREAM)
                .setNumHands(1)
                .setMinHandDetectionConfidence(0.5f)
                .setMinHandPresenceConfidence(0.5f)
                .setMinTrackingConfidence(0.5f)
                .setResultListener { result, image ->
                    latestHandsResult.set(result)
                }
                .setErrorListener { e ->
                    Log.e(TAG, "Hands LIVE_STREAM error", e)
                }
                .build()

            handLandmarker = HandLandmarker.createFromOptions(this, options)
            Log.d(TAG, "âœ“ MediaPipe Hands ì´ˆê¸°í™” ì„±ê³µ")
        } catch (e: Exception) {
            Log.e(TAG, "MediaPipe Hands ì´ˆê¸°í™” ì‹¤íŒ¨", e)
        }
    }

    private fun setupTargetSpinner() {
        val spinnerItems = listOf(TARGET_ANY) + classLabels
        binding.targetSpinner.adapter = ArrayAdapter(this, android.R.layout.simple_spinner_dropdown_item, spinnerItems)
        currentTargetLabel.set(TARGET_ANY)
        binding.targetSpinner.onItemSelectedListener = object : AdapterView.OnItemSelectedListener {
            override fun onItemSelected(p0: AdapterView<*>?, p1: View?, pos: Int, p3: Long) {
                currentTargetLabel.set(spinnerItems.getOrNull(pos) ?: "")
            }
            override fun onNothingSelected(p0: AdapterView<*>?) {}
        }
    }

    private fun getTargetLabel(): String = currentTargetLabel.get()

    /** LOCKED ì‹œ ì‹œê° ë³´ì •: ì´ì „ ë°•ìŠ¤ì™€ IoUê°€ ê°€ì¥ í° íƒ€ê²Ÿ detection ë°˜í™˜. ì—†ìœ¼ë©´ null
     * @param minConfidence occlusion ì‹œ ë” ë‚®ì€ ê¸°ì¤€ ì‚¬ìš© (ì˜ˆ: 0.15f) */
    private fun findTrackedTarget(
        detections: List<OverlayView.DetectionBox>,
        targetLabel: String,
        prevBox: OverlayView.DetectionBox?,
        minConfidence: Float = TARGET_CONFIDENCE_THRESHOLD * 0.5f
    ): OverlayView.DetectionBox? {
        val target = targetLabel.trim()
        if (target.isBlank()) return null

        val candidates = detections.filter { d ->
            (d.label.trim().equals(target, ignoreCase = true) ||
                d.topLabels.any { it.first.trim().equals(target, ignoreCase = true) }) &&
            d.confidence >= minConfidence
        }.map { d ->
            if (d.label.trim().equals(target, ignoreCase = true)) d
            else {
                val conf = d.topLabels.find { it.first.trim().equals(target, ignoreCase = true) }?.second?.div(100f) ?: d.confidence
                d.copy(label = target, confidence = conf, topLabels = listOf(target to (conf * 100).toInt()))
            }
        }

        if (candidates.isEmpty()) return null
        return if (prevBox != null) {
            candidates.maxByOrNull { iou(it.rect, prevBox.rect) }
        } else {
            candidates.maxByOrNull { it.confidence }
        }
    }

    /** íƒ€ê²Ÿì— ë§ëŠ” detectionë§Œ ë°˜í™˜. "ëª¨ë“  ìƒí’ˆ"ì´ë©´ ì „ë¶€, íŠ¹ì • ìƒí’ˆì´ë©´ í•´ë‹¹ ìƒí’ˆë§Œ. */
    private fun filterDetectionsByTarget(detections: List<OverlayView.DetectionBox>, targetLabel: String): List<OverlayView.DetectionBox> {
        val target = targetLabel.trim()
        if (target.isBlank() || target == TARGET_ANY) return detections

        return detections
            .mapNotNull { box ->
                val targetConf = when {
                    box.label.trim().equals(target, ignoreCase = true) -> box.confidence
                    else -> box.topLabels.find { it.first.trim().equals(target, ignoreCase = true) }?.second?.div(100f)
                }
                if (targetConf != null && targetConf >= TARGET_CONFIDENCE_THRESHOLD) {
                    if (box.label.trim().equals(target, ignoreCase = true)) box
                    else box.copy(
                        label = target,
                        confidence = targetConf,
                        topLabels = listOf(target to (targetConf * 100).toInt())
                    )
                } else null
            }
    }

    /** íƒ€ê²Ÿì´ primary label ë˜ëŠ” topLabelsì— ìˆê³  confidence >= 70%ì¸ detection ì¤‘ ìµœê³  í™•ë¥  ì„ íƒ.
     *  "ëª¨ë“  ìƒí’ˆ" ì„ íƒ ì‹œ: confidence >= 70%ì¸ detection ì¤‘ ìµœê³  í™•ë¥  ë°˜í™˜.
     *  @return Pair(ë§¤ì¹­ëœ ë°•ìŠ¤, ì‹¤ì œ 1ìˆœìœ„ ë¼ë²¨). ìŒì„± í”Œë¡œìš°ì—ì„œ 'ì°¾ì•˜ë‹¤' íŒë‹¨ ì‹œ ì‹¤ì œ ë¼ë²¨ ì‚¬ìš©. */
    private fun findTargetMatch(detections: List<OverlayView.DetectionBox>, targetLabel: String): Pair<OverlayView.DetectionBox, String>? {
        val target = targetLabel.trim()
        if (target.isBlank()) return null

        if (target == TARGET_ANY) {
            val box = detections.filter { it.confidence >= TARGET_CONFIDENCE_THRESHOLD }.maxByOrNull { it.confidence }
                ?: return null
            return box to box.label
        }

        return detections
            .mapNotNull { box ->
                val targetConf = when {
                    box.label.trim().equals(target, ignoreCase = true) -> box.confidence
                    else -> box.topLabels.find { it.first.trim().equals(target, ignoreCase = true) }?.second?.div(100f)
                }
                if (targetConf != null && targetConf >= TARGET_CONFIDENCE_THRESHOLD) {
                    val displayBox = if (box.label.trim().equals(target, ignoreCase = true)) box
                    else box.copy(
                        label = target,
                        confidence = targetConf,
                        topLabels = listOf(target to (targetConf * 100).toInt())
                    )
                    Pair(displayBox, box.label)
                } else null
            }
            .maxByOrNull { it.first.confidence }
    }

    /** @param actualPrimaryLabel íƒì§€ëœ 1ìˆœìœ„ ë¼ë²¨(ìŒì„± í”Œë¡œìš°ì—ì„œ ìš”ì²­ ìƒí’ˆê³¼ ë¹„êµìš©). nullì´ë©´ box.label ì‚¬ìš© */
    private fun transitionToLocked(box: OverlayView.DetectionBox, imageWidth: Int, imageHeight: Int, actualPrimaryLabel: String? = null) {
        runOnUiThread {
            searchState = SearchState.LOCKED
            lockedTargetLabel = box.label
            validationFailCount = 0
            frozenImageWidth = imageWidth
            frozenImageHeight = imageHeight
            ttsGrabPlayed = false
            ttsGrabbedPlayed = false
            ttsAskAnotherPlayed = false
            handsOverlapFrameCount = 0
            pinchGrabFrameCount = 0
            binding.resetBtn.visibility = View.GONE
            binding.overlayView.setDetections(listOf(box), imageWidth, imageHeight)
            binding.overlayView.setFrozen(true)
            binding.statusText.text = "ê°ì²´ íƒì§€ë¨. ì†ì„ ë»—ì–´ ì¡ì•„ì£¼ì„¸ìš”."
            if (!ttsDetectedPlayed) {
                ttsDetectedPlayed = true
                speak("ê°ì²´ë¥¼ íƒì§€í–ˆìŠµë‹ˆë‹¤. ì†ì„ ë»—ì–´ ì¡ì•„ì£¼ì„¸ìš”.")
            }
            binding.yoloxStatus.text = "ğŸ”’ ê³ ì •: ${box.label} (ìì´ë¡œ)"
            binding.handsStatus.text = "ğŸ“ ìì´ë¡œ: ON"
            Toast.makeText(this, "íƒ€ê²Ÿ ê³ ì • â†’ ìì´ë¡œ ì¶”ì  ëª¨ë“œ", Toast.LENGTH_SHORT).show()
            if (voiceFlowController?.currentState == VoiceFlowController.VoiceFlowState.SEARCHING_PRODUCT) {
                cancelSearchTimeout()
                val requested = voiceSearchTargetLabel
                val actualLabel = actualPrimaryLabel ?: box.label
                val isRequestedProduct = requested == null || requested == TARGET_ANY || requested == actualLabel
                if (isRequestedProduct) {
                    voiceSearchTargetLabel = null
                    voiceFlowController?.onSearchComplete(true, actualLabel, box.rect, imageWidth, imageHeight)
                }
            }
            startPositionAnnounce()
        }
    }

    private fun transitionToSearching() {
        runOnUiThread {
            stopPositionAnnounce()
            searchState = SearchState.SEARCHING
            lockedTargetLabel = ""
            pendingLockBox = null
            pendingLockCount = 0
            validationFailCount = 0
            wasOccluded = false
            ttsDetectedPlayed = false
            ttsGrabPlayed = false
            ttsGrabbedPlayed = false
            ttsAskAnotherPlayed = false
            handsOverlapFrameCount = 0
            pinchGrabFrameCount = 0
            opticalFlowTracker.reset()
            gyroManager.stopTracking()
            binding.resetBtn.visibility = View.GONE
            binding.overlayView.setDetections(emptyList(), 0, 0)
            binding.overlayView.setFrozen(false)
            binding.statusText.text = "ì°¾ëŠ” ì¤‘: ${getTargetLabel()}"
            stopHandGuidanceTTS()
        }
    }

    /** assets/classes.txt ë¡œë“œ (í•œ ì¤„ = í•œ í´ë˜ìŠ¤, 0ë²ˆì§¸ ì¤„ = class 0). # ì‹œì‘ ì¤„ ë¬´ì‹œ. */
    private fun loadClassLabels() {
        try {
            assets.open("classes.txt").use { stream ->
                BufferedReader(InputStreamReader(stream, Charsets.UTF_8)).use { reader ->
                    classLabels = reader.readLines()
                        .map { it.trim() }
                        .filter { it.isNotEmpty() && !it.startsWith("#") }
                }
            }
            Log.d(TAG, "í´ë˜ìŠ¤ ë¼ë²¨ ${classLabels.size}ê°œ ë¡œë“œ")
        } catch (e: Exception) {
            Log.d(TAG, "classes.txt ì—†ìŒ ë˜ëŠ” ë¡œë“œ ì‹¤íŒ¨ â†’ Object_N í‘œì‹œ", e)
            classLabels = emptyList()
        }
    }

    private fun getClassLabel(classId: Int): String {
        return classLabels.getOrNull(classId)?.takeIf { it.isNotBlank() } ?: "Object_$classId"
    }

    /** YOLOX preproc: BGR, 0~255 float. NCHW [1,3,H,W] ì‹œ ì±„ë„ ì„  ì¶œë ¥ */
    private fun bitmapToFloatBuffer(bitmap: Bitmap, size: Int, isNchw: Boolean = false): ByteBuffer {
        val buffer = ByteBuffer.allocateDirect(4 * size * size * 3)
        buffer.order(ByteOrder.nativeOrder())
        val pixels = IntArray(size * size)
        bitmap.getPixels(pixels, 0, size, 0, 0, size, size)
        if (isNchw) {
            for (c in 0 until 3) {  // B, G, R
                val shift = when (c) { 0 -> 0; 1 -> 8; else -> 16 }
                for (i in pixels.indices) {
                    buffer.putFloat(((pixels[i] shr shift) and 0xFF).toFloat())
                }
            }
        } else {
            for (p in pixels) {
                buffer.putFloat((p and 0xFF).toFloat())
                buffer.putFloat(((p shr 8) and 0xFF).toFloat())
                buffer.putFloat(((p shr 16) and 0xFF).toFloat())
            }
        }
        buffer.rewind()
        return buffer
    }

    private fun initYOLOX() {
        try {
            val modelFilename = "yolox_nano_49cls_float16.tflite"
            val modelFile = loadModelFile(modelFilename)
            val options = Interpreter.Options()
            try {
                gpuDelegate = GpuDelegate()
                options.addDelegate(gpuDelegate)
                options.setAllowFp16PrecisionForFp32(true)
                Log.d(TAG, "ğŸš€ GPU ê°€ì† ì¼œì§ (FP16)")
                runOnUiThread { binding.statusText.text = "YOLOX GPU ì¤€ë¹„" }
            } catch (e: Exception) {
                Log.e(TAG, "âŒ GPU ì‹¤íŒ¨ -> CPU ì „í™˜", e)
                options.setNumThreads(4)
                gpuDelegate = null
                runOnUiThread { binding.statusText.text = "YOLOX CPU ì¤€ë¹„" }
            }
            yoloxInterpreter = Interpreter(modelFile, options)
            val inputShape = yoloxInterpreter!!.getInputTensor(0).shape()
            val inputSize = if (inputShape.size >= 3 && inputShape[1] == 3) inputShape[2] else inputShape[1]
            Log.d(TAG, "YOLOX ë¡œë“œ | $modelFilename | ì…ë ¥ ${inputSize}x${inputSize}")
        } catch (e: Exception) {
            Log.e(TAG, "YOLOX ì´ˆê¸°í™” ì‹¤íŒ¨", e)
            runOnUiThread { binding.statusText.text = "YOLOX ì´ˆê¸°í™” ì‹¤íŒ¨" }
        }
    }

    private fun loadModelFile(modelName: String): MappedByteBuffer {
        val fileDescriptor = assets.openFd(modelName)
        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = inputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        val buffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
        return buffer
    }

    private fun startCamera() {
        val cameraProviderFuture = ProcessCameraProvider.getInstance(this)

        cameraProviderFuture.addListener({
            val cameraProvider = cameraProviderFuture.get()

            // Preview
            val preview = Preview.Builder()
                .build()
                .also {
                    it.setSurfaceProvider(binding.previewView.surfaceProvider)
                }

            // ImageAnalysis
            val imageAnalyzer = ImageAnalysis.Builder()
                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                .build()
                .also {
                    it.setAnalyzer(cameraExecutor, ImageAnalyzer())
                }

            // ì¹´ë©”ë¼ ì„ íƒ
            val cameraSelector = CameraSelector.DEFAULT_BACK_CAMERA

            try {
                cameraProvider.unbindAll()
                cameraProvider.bindToLifecycle(
                    this, cameraSelector, preview, imageAnalyzer
                )
            } catch (e: Exception) {
                Log.e(TAG, "ì¹´ë©”ë¼ ë°”ì¸ë”© ì‹¤íŒ¨", e)
            }

        }, ContextCompat.getMainExecutor(this))
    }

    // YOLOX ì§„ë‹¨ ë¡œê·¸: 3ì´ˆë§ˆë‹¤ í•œ ë²ˆë§Œ ì¶œë ¥ (ë¡œê·¸ ê³¼ë‹¤ ë°©ì§€)
    private var lastYoloxDiagTimeMs = 0L
    private var firstInferenceLogged = false
    private var lastTargetMatchDiagMs = 0L

    // ì´ë¯¸ì§€ ë¶„ì„ê¸°
    private inner class ImageAnalyzer : ImageAnalysis.Analyzer {

        override fun analyze(imageProxy: ImageProxy) {
            val startTime = System.currentTimeMillis()

            // Bitmap ë³€í™˜ (YUV_420_888 â†’ RGB)
            var bitmap = imageProxy.toBitmap()
            if (bitmap == null) {
                imageProxy.close()
                return
            }
            // ì„¸ë¡œ ëª¨ë“œì—ì„œ ì¹´ë©”ë¼ ì„¼ì„œëŠ” ë³´í†µ ê°€ë¡œ â†’ íšŒì „ ì •ë³´ ì ìš©í•´ ëª¨ë¸ ì…ë ¥ì´ í™”ë©´ê³¼ ë§ë„ë¡ í•¨
            val rotationDegrees = imageProxy.imageInfo.rotationDegrees
            if (rotationDegrees != 0) {
                bitmap = BitmapUtils.rotateBitmap(bitmap, rotationDegrees) ?: bitmap
            }

            val w = bitmap.width
            val h = bitmap.height
            val inferenceTime = System.currentTimeMillis() - startTime

            // ì† ì¸ì‹: LOCKEDì¼ ë•Œë§Œ ì‹¤í–‰ (occlusion/optical flowìš©). SEARCHINGì—ì„œëŠ” íŒŒì´í”„ë¼ì¸ ë¹„í™œì„±í™”
            if (searchState == SearchState.LOCKED) {
                sendFrameToHands(bitmap, imageProxy.imageInfo.timestamp)
            }

            when (searchState) {
                SearchState.SEARCHING -> {
                    val detections = runYOLOX(bitmap)
                    val matchResult = findTargetMatch(detections, getTargetLabel())
                    if (matchResult != null) {
                        val (matched, actualPrimaryLabel) = matchResult
                        if (matched.confidence >= TARGET_CONFIDENCE_THRESHOLD) {
                            // ê°™ì€ í´ë˜ìŠ¤ê°€ ì—°ì† ê°ì§€ëëŠ”ì§€ í™•ì¸ (ì˜ëª»ëœ í´ë˜ìŠ¤ ë°©ì§€)
                            val prev = pendingLockBox
                            if (prev != null && prev.label == matched.label &&
                                RectF.intersects(matched.rect, prev.rect)) {
                                pendingLockCount++
                                if (pendingLockCount >= LOCK_CONFIRM_FRAMES) {
                                    pendingLockBox = null
                                    pendingLockCount = 0
                                    transitionToLocked(matched, w, h, actualPrimaryLabel)
                                    frozenBox = matched
                                frozenImageWidth = w
                                frozenImageHeight = h
                                wasOccluded = false
                                opticalFlowTracker.reset()
                                gyroManager.startTracking(matched.rect, w, h)
                                lockedFrameCount = 0
                                validationFailCount = 0
                                    updateFPS()
                                    imageProxy.close()
                                    return
                                }
                            } else {
                                pendingLockBox = matched
                                pendingLockCount = 1
                            }
                        }
                    } else {
                        pendingLockBox = null
                        pendingLockCount = 0
                    }
                    displayResults(filterDetectionsByTarget(detections, getTargetLabel()), inferenceTime, w, h)
                }
                SearchState.LOCKED -> {
                    lockedFrameCount++
                    val nowMs = System.currentTimeMillis()
                    val boxLostDurationMs = nowMs - lastSuccessfulValidationTimeMs
                    val shouldReacquire = boxLostDurationMs >= REACQUIRE_INFERENCE_AFTER_MS
                    val shouldValidate = shouldReacquire || (lockedFrameCount % VALIDATION_INTERVAL) == 0
                    var inferMs = System.currentTimeMillis() - startTime

                    val handsOverlap = frozenBox?.let { box ->
                        isHandOverlappingBox(latestHandsResult.get(), box.rect, w, h)
                    } ?: false

                    val pinchGrab = frozenBox?.let { box ->
                        isPinchGrab(latestHandsResult.get(), box.rect, w, h)
                    } ?: false

                    if (pinchGrab) {
                        pinchGrabFrameCount++
                        if (pinchGrabFrameCount >= 5 && !ttsGrabbedPlayed && !waitingForYesNo) {
                            ttsGrabbedPlayed = true
                            ttsAskAnotherPlayed = true
                            runOnUiThread {
                                stopHandGuidanceTTS()
                                binding.statusText.text = "ë‹¤ë¥¸ ë¬¼ê±´ì„ ì°¾ìœ¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                                speak("ê°ì²´ë¥¼ ì¡ì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë¬¼ê±´ì„ ì°¾ìœ¼ì‹œê² ìŠµë‹ˆê¹Œ?") {
                                    runOnUiThread {
                                        waitingForYesNo = true
                                        startSTTForYesNo()
                                    }
                                }
                            }
                        }
                    } else {
                        pinchGrabFrameCount = 0
                    }

                    gyroManager.suspendUpdates = handsOverlap

                    if (handsOverlap) {
                        if (shouldReacquire) {
                            val detections = runYOLOX(bitmap)
                            inferMs = System.currentTimeMillis() - startTime
                            val minConf = 0.18f
                            val tracked = findTrackedTarget(detections, lockedTargetLabel, frozenBox, minConf)
                            if (tracked != null) {
                                lastSuccessfulValidationTimeMs = System.currentTimeMillis()
                                gyroManager.correctPosition(tracked.rect)
                                frozenBox = tracked.copy(rotationDegrees = 0f)
                                frozenImageWidth = w
                                frozenImageHeight = h
                            }
                        } else {
                            val handRect = mergedHandRect(latestHandsResult.get(), w, h)
                            val flow = opticalFlowTracker.update(bitmap, handRect, frozenBox?.rect)
                            flow?.let { (dx, dy) ->
                                val box = frozenBox ?: return@let
                                val r = box.rect
                                val newRect = RectF(r.left + dx, r.top + dy, r.right + dx, r.bottom + dy)
                                gyroManager.correctPosition(newRect)
                                frozenBox = box.copy(rect = newRect)
                            }
                        }
                    } else {
                        // occlusion í•´ì œ â†’ gyro ê¸°ì € ë™ê¸°í™”
                        if (wasOccluded) {
                            frozenBox?.rect?.let { gyroManager.correctPosition(it) }
                        }
                        if (shouldValidate) {
                            val detections = runYOLOX(bitmap)
                            inferMs = System.currentTimeMillis() - startTime
                            val minConf = if (shouldReacquire) 0.18f else 0.22f
                            val tracked = findTrackedTarget(detections, lockedTargetLabel, frozenBox, minConf)
                            if (tracked != null) {
                                validationFailCount = 0
                                // í•œ í”„ë ˆì„ ì í”„ ë°©ì§€: í˜„ì¬ ë°•ìŠ¤ 70% + YOLOX 30% ë¸”ë Œë”©
                                lastSuccessfulValidationTimeMs = System.currentTimeMillis()
                                val cur = frozenBox?.rect ?: tracked.rect
                                val blend = 0.7f
                                val blendedRect = RectF(
                                    cur.left * blend + tracked.rect.left * (1f - blend),
                                    cur.top * blend + tracked.rect.top * (1f - blend),
                                    cur.right * blend + tracked.rect.right * (1f - blend),
                                    cur.bottom * blend + tracked.rect.bottom * (1f - blend)
                                )
                                gyroManager.correctPosition(blendedRect)
                                frozenBox = tracked.copy(rect = blendedRect, rotationDegrees = 0f)
                                frozenImageWidth = w
                                frozenImageHeight = h
                            } else {
                                validationFailCount++
                                if (validationFailCount >= VALIDATION_FAIL_LIMIT) {
                                    validationFailCount = 0
                                    gyroManager.resetToSearchingFromUI()
                                }
                            }
                        }
                    }
                    wasOccluded = handsOverlap

                    val box = frozenBox
                    val boxes = if (box != null) listOf(box) else emptyList()
                    displayResults(boxes, inferMs, frozenImageWidth, frozenImageHeight)
                }
            }

            updateFPS()
            imageProxy.close()
        }

        @androidx.camera.core.ExperimentalGetImage
        private fun ImageProxy.toBitmap(): Bitmap? {
            val image = this.image ?: return null
            // YUV_420_888 â†’ Bitmap ë³€í™˜ (ê°„ë‹¨ ë²„ì „)
            // ì‹¤ì œë¡œëŠ” ë” ìµœì í™”ëœ ë³€í™˜ í•„ìš”
            return BitmapUtils.yuv420ToBitmap(image)
        }
    }

    /** í™”ë©´ì´ ê±°ì˜ ì•ˆ ë³´ì¼ ì •ë„ë¡œ ì–´ë‘ìš°ë©´ true (ì†ìœ¼ë¡œ ê°€ë¦¼ ë“±). threshold ë‚®ì„ìˆ˜ë¡ ì–´ë‘ìš´ ì´ë¯¸ì§€ë„ ì²˜ë¦¬ */
    private fun isImageTooDark(bitmap: Bitmap, threshold: Int = 28): Boolean {
        val w = bitmap.width
        val h = bitmap.height
        if (w == 0 || h == 0) return true
        val step = max(1, min(w, h) / 20)
        var sum = 0L
        var count = 0
        for (y in 0 until h step step) {
            for (x in 0 until w step step) {
                val p = bitmap.getPixel(x, y)
                sum += ((p shr 16) and 0xFF) + ((p shr 8) and 0xFF) + (p and 0xFF)
                count++
            }
        }
        if (count == 0) return true
        val avg = (sum / count) / 3
        return avg < threshold
    }

    private fun runYOLOX(bitmap: Bitmap): List<OverlayView.DetectionBox> {
        if (yoloxInterpreter == null) return emptyList()

        try {
            val inputShape = yoloxInterpreter!!.getInputTensor(0).shape()
            val isNchw = inputShape.size >= 4 && inputShape[1] == 3
            val inputSize = when {
                isNchw -> inputShape[2]
                inputShape.size >= 4 -> inputShape[1]
                else -> inputShape.last()
            }
            val expectedBytes = 4 * inputSize * inputSize * 3
            val preprocBitmap = Bitmap.createScaledBitmap(bitmap, inputSize, inputSize, true)
            val inputBuffer = bitmapToFloatBuffer(preprocBitmap, inputSize, isNchw)
            if (inputBuffer.remaining() != expectedBytes) {
                Log.e(TAG, "YOLOX ì…ë ¥ ë²„í¼ í¬ê¸° ë¶ˆì¼ì¹˜: ${inputBuffer.remaining()} != $expectedBytes")
                return emptyList()
            }
            val inferStart = System.currentTimeMillis()
            val outputShape = yoloxInterpreter!!.getOutputTensor(0).shape()
            val output = Array(outputShape[0]) { Array(outputShape[1]) { FloatArray(outputShape[2]) } }
            yoloxInterpreter!!.run(inputBuffer, output)
            val inferMs = System.currentTimeMillis() - inferStart
            if (isImageTooDark(bitmap)) {
                return emptyList()
            }
            val detections = parseYOLOXOutput(
                output[0],
                outputShape[1],
                outputShape[2],
                bitmap.width,
                bitmap.height,
                inputSize
            )
            if (!firstInferenceLogged) {
                firstInferenceLogged = true
                Log.d(TAG, "YOLOX ì²« ì¶”ë¡  | ì…ë ¥ bitmap ${bitmap.width}x${bitmap.height} â†’ resize ${inputSize}x${inputSize} | ì¶”ë¡  ${inferMs}ms")
            }
            val now = System.currentTimeMillis()
            if (now - lastYoloxDiagTimeMs >= 3000) {
                lastYoloxDiagTimeMs = now
                Log.d(TAG, "YOLOX ì§„ë‹¨ | ì¶”ë¡  ${inferMs}ms | ê°ì§€ ${detections.size}ê°œ maxConf=${String.format("%.2f", lastYoloxMaxConf)}")
            }
            return detections
        } catch (e: Exception) {
            Log.e(TAG, "YOLOX ì¶”ë¡  ì‹¤íŒ¨", e)
            return emptyList()
        }
    }

    private fun bitmapToByteBuffer(bitmap: Bitmap, size: Int): ByteBuffer {
        val buffer = ByteBuffer.allocateDirect(4 * size * size * 3)
        buffer.order(ByteOrder.nativeOrder())

        val pixels = IntArray(size * size)
        bitmap.getPixels(pixels, 0, size, 0, 0, size, size)

        for (pixelValue in pixels) {
            // [ìˆ˜ì •] FP16 ëª¨ë¸ì€ 0~255 ê°’ì„ 0.0~1.0ìœ¼ë¡œ 'ì •ê·œí™”' í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤!
            // ê¸°ì¡´ ì½”ë“œ: buffer.putFloat(...) -> í‹€ë¦¼
            // ìˆ˜ì • ì½”ë“œ: 255.0fë¡œ ë‚˜ëˆ„ê¸°

            buffer.putFloat(((pixelValue shr 16) and 0xFF) / 255.0f) // R
            buffer.putFloat(((pixelValue shr 8) and 0xFF) / 255.0f)  // G
            buffer.putFloat((pixelValue and 0xFF) / 255.0f)          // B
        }

        return buffer
    }

    private fun parseYOLOXOutput(
        output: Array<FloatArray>,
        dim1: Int,
        dim2: Int,
        imageWidth: Int,
        imageHeight: Int,
        inputSize: Int
    ): List<OverlayView.DetectionBox> {
        val numBoxes: Int
        val boxSize: Int
        val isRowMajor: Boolean

        if (dim1 >= dim2) {
            numBoxes = dim1
            boxSize = dim2
            isRowMajor = true
        } else {
            numBoxes = dim2
            boxSize = dim1
            isRowMajor = false
        }

        val isNormalized = if (isRowMajor && output.isNotEmpty() && output[0].size >= 4) {
            maxOf(output[0][0], output[0][1], output[0][2], output[0][3]) <= 1.5f
        } else if (!isRowMajor && output.size >= 4) {
            maxOf(output[0][0], output[1][0], output[2][0], output[3][0]) <= 1.5f
        } else true

        if (!yoloxShapeLogged) {
            yoloxShapeLogged = true
            Log.d(TAG, "YOLOX shape: dim1=$dim1 dim2=$dim2 â†’ numBoxes=$numBoxes boxSize=$boxSize")
        }

        val candidates = mutableListOf<OverlayView.DetectionBox>()
        // 4(box)+1(obj)+N(cls): 85(80), 58(53), 55(50), 54(49)
        val hasObjectness = (boxSize == 85 || boxSize == 58 || boxSize == 55 || boxSize == 54)
        val scoreStart = if (hasObjectness) 5 else 4
        val classCount = (boxSize - scoreStart).coerceAtLeast(1)

        val useSingleScoreFormat = (numBoxes <= 100 && boxSize >= 5)
        val minConfidenceToShow = when {
            useSingleScoreFormat -> 0.35f
            hasObjectness -> 0.45f
            else -> 0.78f
        }

        var maxConfidenceSeen = 0f

        for (j in 0 until numBoxes) {
            val v0: Float
            val v1: Float
            val v2: Float
            val v3: Float
            val classScores = FloatArray(classCount)
            var singleScore = 0f

            if (isRowMajor) {
                val row = output[j]
                if (row.size < boxSize) continue
                v0 = row[0]; v1 = row[1]; v2 = row[2]; v3 = row[3]
                if (row.size > 4) singleScore = row[4]
                for (c in 0 until classCount) classScores[c] = row[scoreStart + c]
            } else {
                v0 = output[0][j]; v1 = output[1][j]; v2 = output[2][j]; v3 = output[3][j]
                if (dim1 > 4) singleScore = output[4][j]
                for (c in 0 until classCount) classScores[c] = output[scoreStart + c][j]
            }

            val objScore = singleScore.coerceIn(0f, 1f)
            val topK = 3
            val topClassIds = classScores.indices
                .map { c ->
                    var rs = classScores[c]
                    if (rs > 1f || rs < 0f) rs = 1f / (1f + exp(-rs))
                    c to (objScore * rs).coerceIn(0f, 1f)
                }
                .sortedByDescending { it.second }
                .take(topK)
            val confidence = topClassIds.firstOrNull()?.second ?: 0f
            if (confidence > maxConfidenceSeen) maxConfidenceSeen = confidence
            if (confidence < minConfidenceToShow) continue

            // 50% ì´ìƒì¸ í´ë˜ìŠ¤ë§Œ í‘œì‹œ (ìƒìœ„ 3ê°œ ì¤‘ì—ì„œ)
            val topLabels = topClassIds
                .filter { (_, conf) -> conf >= 0.5f }
                .map { (cid, conf) ->
                    getClassLabel(cid) to (conf * 100).toInt()
                }

            // ì¢Œí‘œ: ì •ê·œí™” 0~1ì´ê³  v2>v0, v3>v1 ì´ë©´ (x1,y1,x2,y2). ì•„ë‹ˆë©´ (cx,cy,w,h).
            val left: Float
            val top: Float
            val right: Float
            val bottom: Float
            if (isNormalized && v2 > v0 && v3 > v1) {
                left = (v0 * imageWidth).coerceIn(0f, imageWidth.toFloat())
                top = (v1 * imageHeight).coerceIn(0f, imageHeight.toFloat())
                right = (v2 * imageWidth).coerceIn(0f, imageWidth.toFloat())
                bottom = (v3 * imageHeight).coerceIn(0f, imageHeight.toFloat())
            } else {
                if (isNormalized) {
                    val cx = v0.coerceIn(0f, 1f) * imageWidth
                    val cy = v1.coerceIn(0f, 1f) * imageHeight
                    val w = (v2.coerceIn(0f, 1f) * imageWidth) / 2f
                    val h = (v3.coerceIn(0f, 1f) * imageHeight) / 2f
                    left = max(0f, cx - w)
                    top = max(0f, cy - h)
                    right = min(imageWidth.toFloat(), cx + w)
                    bottom = min(imageHeight.toFloat(), cy + h)
                } else {
                    val cx = v0 / inputSize * imageWidth
                    val cy = v1 / inputSize * imageHeight
                    val w = (v2 / inputSize * imageWidth) / 2f
                    val h = (v3 / inputSize * imageHeight) / 2f
                    left = max(0f, cx - w)
                    top = max(0f, cy - h)
                    right = min(imageWidth.toFloat(), cx + w)
                    bottom = min(imageHeight.toFloat(), cy + h)
                }
            }

            if (right <= left || bottom <= top) continue

            candidates.add(
                OverlayView.DetectionBox(
                    label = topLabels.firstOrNull()?.first ?: "",
                    confidence = confidence,
                    rect = android.graphics.RectF(left, top, right, bottom),
                    topLabels = topLabels
                )
            )
        }

        lastYoloxMaxConf = maxConfidenceSeen
        return nms(candidates, iouThreshold = 0.6f)
    }

    private fun nms(boxes: List<OverlayView.DetectionBox>, iouThreshold: Float): List<OverlayView.DetectionBox> {
        val sorted = boxes.sortedByDescending { it.confidence }
        val picked = mutableListOf<OverlayView.DetectionBox>()
        val used = BooleanArray(sorted.size)

        for (i in sorted.indices) {
            if (used[i]) continue
            picked.add(sorted[i])
            for (j in i + 1 until sorted.size) {
                if (used[j]) continue
                if (iou(sorted[i].rect, sorted[j].rect) > iouThreshold) used[j] = true
            }
        }
        return picked
    }

    /** ì† ëœë“œë§ˆí¬(ì •ê·œí™” 0~1) â†’ ì´ë¯¸ì§€ ì¢Œí‘œ RectF */
    private fun handLandmarksToRect(landmarks: List<NormalizedLandmark>, imageWidth: Int, imageHeight: Int): RectF {
        if (landmarks.isEmpty()) return RectF(0f, 0f, 0f, 0f)
        val xs = landmarks.map { it.x().coerceIn(0f, 1f) * imageWidth }
        val ys = landmarks.map { it.y().coerceIn(0f, 1f) * imageHeight }
        return RectF(xs.min(), ys.min(), xs.max(), ys.max())
    }

    /** ì† ëœë“œë§ˆí¬ë“¤ â†’ ëª¨ë“  ì†ì„ í¬í•¨í•˜ëŠ” ë‹¨ì¼ RectF (optical flow ë§ˆìŠ¤í‚¹ìš©) */
    private fun mergedHandRect(handsResult: HandLandmarkerResult?, imageWidth: Int, imageHeight: Int): RectF? {
        val landmarks = handsResult?.landmarks() ?: return null
        if (landmarks.isEmpty()) return null
        var union: RectF? = null
        for (hand in landmarks) {
            val r = handLandmarksToRect(hand, imageWidth, imageHeight)
            union = if (union == null) r else {
                val u = RectF(union)
                u.union(r)
                u
            }
        }
        return union
    }

    /** ì†ì´ ë°•ìŠ¤ì™€ ê²¹ì¹˜ë©´ true (occlusion, optical flowìš©) */
    private fun isHandOverlappingBox(handsResult: HandLandmarkerResult?, boxRect: RectF, imageWidth: Int, imageHeight: Int): Boolean {
        val landmarks = handsResult?.landmarks() ?: return false
        if (imageWidth <= 0 || imageHeight <= 0) return false
        return landmarks.any { hand ->
            val handRect = handLandmarksToRect(hand, imageWidth, imageHeight)
            iou(handRect, boxRect) > 0.1f
        }
    }

    /** ëœë“œë§ˆí¬ë¥¼ ì´ë¯¸ì§€ ì¢Œí‘œ (x,y) ë¡œ ë³€í™˜ */
    private
    fun landmarkToPoint(hand: List<NormalizedLandmark>, index: Int, imageWidth: Int, imageHeight: Int): Pair<Float, Float>? {
        if (index < 0 || index >= hand.size) return null
        val lm = hand[index]
        return Pair(
            lm.x().coerceIn(0f, 1f) * imageWidth,
            lm.y().coerceIn(0f, 1f) * imageHeight
        )
    }

    /**
     * ì¡ê¸° íŒì •: ì—„ì§€ì™€ ê²€ì§€ ëì´ **ê°ì²´(ë°•ìŠ¤)ë¥¼ ì‹¤ì œë¡œ í„°ì¹˜Â·ì¡ì€** ê²½ìš°ë§Œ true.
     * - ì—„ì§€ ë(4), ê²€ì§€ ë(8)ì´ ë°•ìŠ¤ ìœ„ ë˜ëŠ” ë°•ìŠ¤ ê°€ì¥ìë¦¬ ê·¼ì²˜(í„°ì¹˜ í—ˆìš© ë§ˆì§„) ì•ˆì— ìˆì–´ì•¼ í•¨.
     * - "ì†ë§Œ ë‚˜ì˜¤ë©´" ì¡ê¸° X â†’ ë°˜ë“œì‹œ ì—„ì§€Â·ê²€ì§€ê°€ ê°ì²´ ì˜ì—­ì„ í„°ì¹˜í•œ ìƒíƒœì—¬ì•¼ í•¨.
     * - ë‚˜ë¨¸ì§€ ì†ê°€ë½(ì¤‘ì§€Â·ì•½ì§€Â·ì†Œì§€) ì¤‘ 2ê°œ ì´ìƒì´ ë°•ìŠ¤ ë°–ì´ë©´ ì¡ëŠ” ìì„¸ë¡œ ì¶”ê°€ ì¸ì •.
     */
    private fun isPinchGrab(handsResult: HandLandmarkerResult?, boxRect: RectF, imageWidth: Int, imageHeight: Int): Boolean {
        val landmarks = handsResult?.landmarks() ?: return false
        if (imageWidth <= 0 || imageHeight <= 0) return false
        val boxW = max(boxRect.width(), 20f)
        val boxH = max(boxRect.height(), 20f)
        val touchMargin = max(boxW, boxH) * 0.02f
        val touchBox = RectF(
            boxRect.left - touchMargin,
            boxRect.top - touchMargin,
            boxRect.right + touchMargin,
            boxRect.bottom + touchMargin
        )
        for (hand in landmarks) {
            if (hand.size < 21) continue
            val thumb = landmarkToPoint(hand, THUMB_TIP, imageWidth, imageHeight) ?: continue
            val index = landmarkToPoint(hand, INDEX_TIP, imageWidth, imageHeight) ?: continue
            val thumbOnObject = touchBox.contains(thumb.first, thumb.second)
            val indexOnObject = touchBox.contains(index.first, index.second)
            if (!thumbOnObject || !indexOnObject) continue

            val middle = landmarkToPoint(hand, MIDDLE_TIP, imageWidth, imageHeight)
            val ring = landmarkToPoint(hand, RING_TIP, imageWidth, imageHeight)
            val pinky = landmarkToPoint(hand, PINKY_TIP, imageWidth, imageHeight)
            val middleBehind = middle != null && !boxRect.contains(middle.first, middle.second)
            val ringBehind = ring != null && !boxRect.contains(ring.first, ring.second)
            val pinkyBehind = pinky != null && !boxRect.contains(pinky.first, pinky.second)
            val behindCount = listOf(middleBehind, ringBehind, pinkyBehind).count { it }
            if (behindCount >= 2) return true
        }
        return false
    }

    /** LOCKED ìƒíƒœì—ì„œ ì† ìœ„ì¹˜ì— ë”°ë¥¸ TTS ì•ˆë‚´ ë¬¸êµ¬ (ì†ì„ ë” ë»—ì–´ì£¼ì„¸ìš”, ì•ìœ¼ë¡œ ì›€ì§ì—¬ì£¼ì„¸ìš” ë“±) */
    private fun buildHandPositionGuidance(handsResult: HandLandmarkerResult?, boxRect: RectF, imageWidth: Int, imageHeight: Int): String? {
        val landmarks = handsResult?.landmarks() ?: return null
        if (landmarks.isEmpty() || imageWidth <= 0 || imageHeight <= 0) return null
        val hand = landmarks.first()
        if (hand.size <= WRIST) return null
        val wrist = landmarkToPoint(hand, WRIST, imageWidth, imageHeight) ?: return null
        val boxCenterX = (boxRect.left + boxRect.right) / 2f
        val boxCenterY = (boxRect.top + boxRect.bottom) / 2f
        val dx = (wrist.first - boxCenterX) / imageWidth
        val dy = (wrist.second - boxCenterY) / imageHeight
        val dist = sqrt(dx * dx + dy * dy)

        return when {
            dist > 0.45f -> "ì†ì„ ë” ë»—ì–´ì£¼ì„¸ìš”. ì•ìœ¼ë¡œ ì¡°ê¸ˆ ë” ì›€ì§ì—¬ì£¼ì„¸ìš”."
            dist > 0.3f -> "ì¡°ê¸ˆ ë” ì•ìœ¼ë¡œ ë‹¤ê°€ê°€ ì£¼ì„¸ìš”."
            dx > 0.15f -> "ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¡°ê¸ˆ ì›€ì§ì—¬ì£¼ì„¸ìš”."
            dx < -0.15f -> "ì™¼ìª½ìœ¼ë¡œ ì¡°ê¸ˆ ì›€ì§ì—¬ì£¼ì„¸ìš”."
            dy > 0.12f -> "ì•„ë˜ë¡œ ì¡°ê¸ˆ ì›€ì§ì—¬ì£¼ì„¸ìš”."
            dy < -0.12f -> "ìœ„ë¡œ ì¡°ê¸ˆ ì›€ì§ì—¬ì£¼ì„¸ìš”."
            else -> null
        }
    }

    private fun startHandGuidanceTTS() {
        stopHandGuidanceTTS()
        handGuidanceRunnable = object : Runnable {
            override fun run() {
                if (searchState != SearchState.LOCKED || ttsGrabbedPlayed || waitingForYesNo) return
                val box = frozenBox ?: return
                val w = frozenImageWidth
                val h = frozenImageHeight
                if (w <= 0 || h <= 0) return
                val guidance = buildHandPositionGuidance(latestHandsResult.get(), box.rect, w, h)
                if (!guidance.isNullOrBlank()) {
                    lastHandGuidanceTimeMs = System.currentTimeMillis()
                    speak(guidance)
                }
                handGuidanceHandler.postDelayed(this, HAND_GUIDANCE_INTERVAL_MS)
            }
        }
        handGuidanceHandler.postDelayed(handGuidanceRunnable!!, HAND_GUIDANCE_INTERVAL_MS)
    }

    private fun stopHandGuidanceTTS() {
        handGuidanceRunnable?.let { handGuidanceHandler.removeCallbacks(it) }
        handGuidanceRunnable = null
    }

    /** LIVE_STREAM: í”„ë ˆì„ë§Œ ë„˜ê¸°ê³  ì¦‰ì‹œ return. ê²°ê³¼ëŠ” resultListener ì½œë°±ìœ¼ë¡œ ì˜´. */
    private fun sendFrameToHands(bitmap: Bitmap, timestampNs: Long) {
        if (handLandmarker == null) return
        try {
            val mpImage = BitmapImageBuilder(bitmap).build()
            val timestampMs = timestampNs / 1_000_000
            handLandmarker!!.detectAsync(mpImage, timestampMs)
        } catch (e: Exception) {
            Log.e(TAG, "Hands detectAsync ì‹¤íŒ¨", e)
        }
    }

    private fun iou(a: android.graphics.RectF, b: android.graphics.RectF): Float {
        val interLeft = max(a.left, b.left)
        val interTop = max(a.top, b.top)
        val interRight = min(a.right, b.right)
        val interBottom = min(a.bottom, b.bottom)
        val interW = max(0f, interRight - interLeft)
        val interH = max(0f, interBottom - interTop)
        val interArea = interW * interH
        val areaA = a.width() * a.height()
        val areaB = b.width() * b.height()
        return interArea / (areaA + areaB - interArea + 1e-6f)
    }

    private fun displayResults(
        detections: List<OverlayView.DetectionBox>,
        inferenceTime: Long,
        imageWidth: Int,
        imageHeight: Int
    ) {
        runOnUiThread {
            binding.overlayView.setDetections(detections, imageWidth, imageHeight)
            binding.overlayView.setHands(
                if (searchState == SearchState.LOCKED) latestHandsResult.get() else null
            )

            if (!waitingForYesNo) {
                when (searchState) {
                    SearchState.SEARCHING -> binding.statusText.text = "ì°¾ëŠ” ì¤‘: ${getTargetLabel()}"
                    SearchState.LOCKED -> {
                        if (frozenBox != null && !ttsGrabbedPlayed) {
                            binding.statusText.text = "ì†ì„ ë»—ì–´ ì¡ì•„ì£¼ì„¸ìš”"
                        }
                    }
                }
            }
        }
    }

    private fun updateFPS() {
        frameCount++
        val currentTime = System.currentTimeMillis()
        if (currentTime - lastFpsTime >= 1000) {
            frameCount = 0
            lastFpsTime = currentTime
        }
    }

    private fun allPermissionsGranted() = REQUIRED_PERMISSIONS.all {
        ContextCompat.checkSelfPermission(baseContext, it) == PackageManager.PERMISSION_GRANTED
    }

    override fun onRequestPermissionsResult(
        requestCode: Int,
        permissions: Array<out String>,
        grantResults: IntArray
    ) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQUEST_CODE_PERMISSIONS) {
            if (allPermissionsGranted()) {
                showFirstScreen()
                playWelcomeTTS()
            } else {
                Toast.makeText(this, "ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
                finish()
            }
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        cancelSearchTimeout()
        stopPositionAnnounce()
        cameraExecutor.shutdown()
        yoloxInterpreter?.close()
        gpuDelegate?.close()
        gyroManager.stopTracking()
        sttManager?.release()
        ttsManager?.release()
        beepPlayer?.release()
        handLandmarker?.close()
        if (::gyroManager.isInitialized) gyroManager.stopTracking()
    }

    companion object {
        private const val TAG = "GrabIT_Test"
        private var yoloxShapeLogged = false
        private const val THUMB_TIP = 4
        private const val INDEX_TIP = 8
        private const val MIDDLE_TIP = 12
        private const val RING_TIP = 16
        private const val PINKY_TIP = 20
        private const val WRIST = 0
    }
}
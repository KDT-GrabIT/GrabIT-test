package com.example.grabitTest

import android.Manifest
import android.content.pm.PackageManager
import android.graphics.Bitmap
import android.os.Bundle
import android.util.Log
import android.view.View
import android.widget.AdapterView
import android.widget.ArrayAdapter
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import android.graphics.RectF
import com.example.grabitTest.databinding.ActivityMainBinding
import com.google.mediapipe.framework.image.BitmapImageBuilder
import com.google.mediapipe.tasks.core.BaseOptions
import com.google.mediapipe.tasks.vision.core.RunningMode
import com.google.mediapipe.tasks.vision.handlandmarker.HandLandmarker
import com.google.mediapipe.tasks.vision.handlandmarker.HandLandmarkerResult
import com.google.mediapipe.tasks.components.containers.NormalizedLandmark
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.gpu.GpuDelegate
import java.io.BufferedReader
import java.io.InputStreamReader
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel
import java.util.concurrent.ExecutorService
import java.util.concurrent.Executors
import java.util.concurrent.atomic.AtomicReference
import kotlin.math.exp
import kotlin.math.max
import kotlin.math.min

class MainActivity : AppCompatActivity() {

    private lateinit var binding: ActivityMainBinding
    private lateinit var cameraExecutor: ExecutorService

    // AI ëª¨ë¸
    private var yoloxInterpreter: Interpreter? = null
    private var gpuDelegate: GpuDelegate? = null
    private var handLandmarker: HandLandmarker? = null

    // LIVE_STREAM: Hands ê²°ê³¼ëŠ” ì½œë°±ìœ¼ë¡œ ì˜´ â†’ ìµœì‹  ê°’ë§Œ ë³´ê´€
    private val latestHandsResult = AtomicReference<HandLandmarkerResult?>(null)

    // FPS ì¸¡ì •
    private var frameCount = 0
    private var lastFpsTime = System.currentTimeMillis()

    private var lastYoloxMaxConf = 0f

    /** í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ ì´ë¦„ (assets/classes.txt, í•œ ì¤„ì— í•˜ë‚˜, # ë¬´ì‹œ) */
    private var classLabels: List<String> = emptyList()

    enum class SearchState { SEARCHING, LOCKED }
    private var searchState = SearchState.SEARCHING
    private var frozenBox: OverlayView.DetectionBox? = null
    private var frozenImageWidth = 0
    private var frozenImageHeight = 0
    /** State Bì—ì„œ ê³„ì† ì¶”ì í•  íƒ€ê²Ÿ ë¼ë²¨ (ë½ ì‹œì ì˜ box.label) */
    private var lockedTargetLabel: String = ""

    /** ê°™ì€ ê°ì²´ê°€ ì—°ì† Ní”„ë ˆì„ ê°ì§€ëì„ ë•Œë§Œ ê³ ì • (ì˜ëª»ëœ í´ë˜ìŠ¤ ë°©ì§€) */
    private val LOCK_CONFIRM_FRAMES = 3
    private var pendingLockBox: OverlayView.DetectionBox? = null
    private var pendingLockCount = 0

    /** LOCKED ì‹œ YOLOX ê²€ì¦+ë³´ì •: Ní”„ë ˆì„ë§ˆë‹¤ 1íšŒ ì‹¤í–‰ (ìì´ë¡œ + ì‹œê° ë³´ì •) */
    private val VALIDATION_INTERVAL = 4
    private val VALIDATION_FAIL_LIMIT = 3
    private var validationFailCount = 0
    private var lockedFrameCount = 0

    private lateinit var gyroManager: GyroTrackingManager
    private val opticalFlowTracker = OpticalFlowTracker()

    private var wasOccluded = false  // occlusion â†’ non-occlusion ì „í™˜ ì‹œ gyro ë™ê¸°í™”ìš©

    private val TARGET_CONFIDENCE_THRESHOLD = 0.6f  // 60% ì´ìƒ í™•ì‹  ì‹œì—ë§Œ ê³ ì • (ì˜ëª»ëœ í´ë˜ìŠ¤ ë°©ì§€)
    private val TARGET_ANY = "ëª¨ë“  ìƒí’ˆ"
    private val currentTargetLabel = AtomicReference<String>("")

    private val REQUIRED_PERMISSIONS = arrayOf(Manifest.permission.CAMERA)
    private val REQUEST_CODE_PERMISSIONS = 10

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        binding = ActivityMainBinding.inflate(layoutInflater)
        setContentView(binding.root)

        cameraExecutor = Executors.newSingleThreadExecutor()

        loadClassLabels()
        initYOLOX()
        initMediaPipeHands()
        setupTargetSpinner()
        initGyroTrackingManager()

        binding.startSearchBtn.setOnClickListener { onStartSearchClicked() }
        binding.resetBtn.setOnClickListener { gyroManager.resetToSearchingFromUI() }

        if (allPermissionsGranted()) {
            binding.startSearchBtn.visibility = View.VISIBLE
        } else {
            binding.startSearchBtn.visibility = View.GONE
            ActivityCompat.requestPermissions(
                this, REQUIRED_PERMISSIONS, REQUEST_CODE_PERMISSIONS
            )
        }
    }

    private fun onStartSearchClicked() {
        binding.startSearchBtn.visibility = View.GONE
        binding.previewView.visibility = View.VISIBLE
        binding.overlayView.visibility = View.VISIBLE
        startCamera()
    }

    private fun initGyroTrackingManager() {
        gyroManager = GyroTrackingManager(
            context = this,
            onBoxUpdate = { update: BoxUpdate ->
                runOnUiThread {
                    val box = OverlayView.DetectionBox(
                        label = lockedTargetLabel,
                        confidence = 0.9f,
                        rect = update.rect,
                        topLabels = listOf(lockedTargetLabel to 90),
                        rotationDegrees = update.rotationDegrees
                    )
                    frozenBox = box
                    binding.overlayView.setDetections(listOf(box), frozenImageWidth, frozenImageHeight)
                }
            },
            onTrackingLost = { transitionToSearching() }
        )
    }

    private fun initMediaPipeHands() {
        try {
            val baseOptions = BaseOptions.builder()
                .setModelAssetPath("hand_landmarker.task")
                .build()

            val options = HandLandmarker.HandLandmarkerOptions.builder()
                .setBaseOptions(baseOptions)
                .setRunningMode(RunningMode.LIVE_STREAM)
                .setNumHands(2)
                .setMinHandDetectionConfidence(0.5f)
                .setMinHandPresenceConfidence(0.5f)
                .setMinTrackingConfidence(0.5f)
                .setResultListener { result, image ->
                    latestHandsResult.set(result)
                }
                .setErrorListener { e ->
                    Log.e(TAG, "Hands LIVE_STREAM error", e)
                }
                .build()

            handLandmarker = HandLandmarker.createFromOptions(this, options)
            Log.d(TAG, "âœ“ MediaPipe Hands ì´ˆê¸°í™” ì„±ê³µ")
        } catch (e: Exception) {
            Log.e(TAG, "MediaPipe Hands ì´ˆê¸°í™” ì‹¤íŒ¨", e)
        }
    }

    private fun setupTargetSpinner() {
        val spinnerItems = listOf(TARGET_ANY) + classLabels
        binding.targetSpinner.adapter = ArrayAdapter(this, android.R.layout.simple_spinner_dropdown_item, spinnerItems)
        currentTargetLabel.set(TARGET_ANY)
        binding.targetSpinner.onItemSelectedListener = object : AdapterView.OnItemSelectedListener {
            override fun onItemSelected(p0: AdapterView<*>?, p1: View?, pos: Int, p3: Long) {
                currentTargetLabel.set(spinnerItems.getOrNull(pos) ?: "")
            }
            override fun onNothingSelected(p0: AdapterView<*>?) {}
        }
    }

    private fun getTargetLabel(): String = currentTargetLabel.get()

    /** LOCKED ì‹œ ì‹œê° ë³´ì •: ì´ì „ ë°•ìŠ¤ì™€ IoUê°€ ê°€ì¥ í° íƒ€ê²Ÿ detection ë°˜í™˜. ì—†ìœ¼ë©´ null
     * @param minConfidence occlusion ì‹œ ë” ë‚®ì€ ê¸°ì¤€ ì‚¬ìš© (ì˜ˆ: 0.15f) */
    private fun findTrackedTarget(
        detections: List<OverlayView.DetectionBox>,
        targetLabel: String,
        prevBox: OverlayView.DetectionBox?,
        minConfidence: Float = TARGET_CONFIDENCE_THRESHOLD * 0.5f
    ): OverlayView.DetectionBox? {
        val target = targetLabel.trim()
        if (target.isBlank()) return null

        val candidates = detections.filter { d ->
            (d.label.trim().equals(target, ignoreCase = true) ||
                d.topLabels.any { it.first.trim().equals(target, ignoreCase = true) }) &&
            d.confidence >= minConfidence
        }.map { d ->
            if (d.label.trim().equals(target, ignoreCase = true)) d
            else {
                val conf = d.topLabels.find { it.first.trim().equals(target, ignoreCase = true) }?.second?.div(100f) ?: d.confidence
                d.copy(label = target, confidence = conf, topLabels = listOf(target to (conf * 100).toInt()))
            }
        }

        if (candidates.isEmpty()) return null
        return if (prevBox != null) {
            candidates.maxByOrNull { iou(it.rect, prevBox.rect) }
        } else {
            candidates.maxByOrNull { it.confidence }
        }
    }

    /** íƒ€ê²Ÿì— ë§ëŠ” detectionë§Œ ë°˜í™˜. "ëª¨ë“  ìƒí’ˆ"ì´ë©´ ì „ë¶€, íŠ¹ì • ìƒí’ˆì´ë©´ í•´ë‹¹ ìƒí’ˆë§Œ. */
    private fun filterDetectionsByTarget(detections: List<OverlayView.DetectionBox>, targetLabel: String): List<OverlayView.DetectionBox> {
        val target = targetLabel.trim()
        if (target.isBlank() || target == TARGET_ANY) return detections

        return detections
            .mapNotNull { box ->
                val targetConf = when {
                    box.label.trim().equals(target, ignoreCase = true) -> box.confidence
                    else -> box.topLabels.find { it.first.trim().equals(target, ignoreCase = true) }?.second?.div(100f)
                }
                if (targetConf != null && targetConf >= TARGET_CONFIDENCE_THRESHOLD) {
                    if (box.label.trim().equals(target, ignoreCase = true)) box
                    else box.copy(
                        label = target,
                        confidence = targetConf,
                        topLabels = listOf(target to (targetConf * 100).toInt())
                    )
                } else null
            }
    }

    /** íƒ€ê²Ÿì´ primary label ë˜ëŠ” topLabelsì— ìˆê³  confidence >= 70%ì¸ detection ì¤‘ ìµœê³  í™•ë¥  ì„ íƒ.
     *  "ëª¨ë“  ìƒí’ˆ" ì„ íƒ ì‹œ: confidence >= 70%ì¸ detection ì¤‘ ìµœê³  í™•ë¥  ë°˜í™˜ */
    private fun findTargetMatch(detections: List<OverlayView.DetectionBox>, targetLabel: String): OverlayView.DetectionBox? {
        val target = targetLabel.trim()
        if (target.isBlank()) return null

        if (target == TARGET_ANY) {
            return detections.filter { it.confidence >= TARGET_CONFIDENCE_THRESHOLD }.maxByOrNull { it.confidence }
        }

        return detections
            .mapNotNull { box ->
                val targetConf = when {
                    box.label.trim().equals(target, ignoreCase = true) -> box.confidence
                    else -> box.topLabels.find { it.first.trim().equals(target, ignoreCase = true) }?.second?.div(100f)
                }
                if (targetConf != null && targetConf >= TARGET_CONFIDENCE_THRESHOLD) {
                    if (box.label.trim().equals(target, ignoreCase = true)) box
                    else box.copy(
                        label = target,
                        confidence = targetConf,
                        topLabels = listOf(target to (targetConf * 100).toInt())
                    )
                } else null
            }
            .maxByOrNull { it.confidence }
    }

    private fun transitionToLocked(box: OverlayView.DetectionBox, imageWidth: Int, imageHeight: Int) {
        runOnUiThread {
            searchState = SearchState.LOCKED
            lockedTargetLabel = box.label
            validationFailCount = 0
            frozenImageWidth = imageWidth
            frozenImageHeight = imageHeight
            binding.resetBtn.visibility = View.VISIBLE
            binding.overlayView.setDetections(listOf(box), imageWidth, imageHeight)
            binding.overlayView.setFrozen(true)
            binding.yoloxStatus.text = "ğŸ”’ ê³ ì •: ${box.label} (ìì´ë¡œ)"
            binding.handsStatus.text = "ğŸ“ ìì´ë¡œ: ON"
            Toast.makeText(this, "íƒ€ê²Ÿ ê³ ì • â†’ ìì´ë¡œ ì¶”ì  ëª¨ë“œ", Toast.LENGTH_SHORT).show()
        }
    }

    private fun transitionToSearching() {
        runOnUiThread {
            searchState = SearchState.SEARCHING
            lockedTargetLabel = ""
            pendingLockBox = null
            pendingLockCount = 0
            validationFailCount = 0
            wasOccluded = false
            opticalFlowTracker.reset()
            gyroManager.stopTracking()
            binding.resetBtn.visibility = View.GONE
            binding.overlayView.setDetections(emptyList(), 0, 0)
            binding.overlayView.setFrozen(false)
            binding.yoloxStatus.text = "ğŸ” íƒìƒ‰ ì¤‘..."
            binding.handsStatus.text = "ğŸ“ ìì´ë¡œ: OFF"
        }
    }

    /** assets/classes.txt ë¡œë“œ (í•œ ì¤„ = í•œ í´ë˜ìŠ¤, 0ë²ˆì§¸ ì¤„ = class 0). # ì‹œì‘ ì¤„ ë¬´ì‹œ. */
    private fun loadClassLabels() {
        try {
            assets.open("classes.txt").use { stream ->
                BufferedReader(InputStreamReader(stream, Charsets.UTF_8)).use { reader ->
                    classLabels = reader.readLines()
                        .map { it.trim() }
                        .filter { it.isNotEmpty() && !it.startsWith("#") }
                }
            }
            Log.d(TAG, "í´ë˜ìŠ¤ ë¼ë²¨ ${classLabels.size}ê°œ ë¡œë“œ")
        } catch (e: Exception) {
            Log.d(TAG, "classes.txt ì—†ìŒ ë˜ëŠ” ë¡œë“œ ì‹¤íŒ¨ â†’ Object_N í‘œì‹œ", e)
            classLabels = emptyList()
        }
    }

    private fun getClassLabel(classId: Int): String {
        return classLabels.getOrNull(classId)?.takeIf { it.isNotBlank() } ?: "Object_$classId"
    }

    /** YOLOX preproc: BGR, 0~255 float. NCHW [1,3,H,W] ì‹œ ì±„ë„ ì„  ì¶œë ¥ */
    private fun bitmapToFloatBuffer(bitmap: Bitmap, size: Int, isNchw: Boolean = false): ByteBuffer {
        val buffer = ByteBuffer.allocateDirect(4 * size * size * 3)
        buffer.order(ByteOrder.nativeOrder())
        val pixels = IntArray(size * size)
        bitmap.getPixels(pixels, 0, size, 0, 0, size, size)
        if (isNchw) {
            for (c in 0 until 3) {  // B, G, R
                val shift = when (c) { 0 -> 0; 1 -> 8; else -> 16 }
                for (i in pixels.indices) {
                    buffer.putFloat(((pixels[i] shr shift) and 0xFF).toFloat())
                }
            }
        } else {
            for (p in pixels) {
                buffer.putFloat((p and 0xFF).toFloat())
                buffer.putFloat(((p shr 8) and 0xFF).toFloat())
                buffer.putFloat(((p shr 16) and 0xFF).toFloat())
            }
        }
        buffer.rewind()
        return buffer
    }

    private fun initYOLOX() {
        try {
            val modelFilename = "yolox_nano_49cls_float16.tflite"
            val modelFile = loadModelFile(modelFilename)
            val options = Interpreter.Options()
            try {
                gpuDelegate = GpuDelegate()
                options.addDelegate(gpuDelegate)
                options.setAllowFp16PrecisionForFp32(true)
                Log.d(TAG, "ğŸš€ GPU ê°€ì† ì¼œì§ (FP16)")
                runOnUiThread { binding.yoloxStatus.text = "ğŸ“¦ YOLOX: GPU (FP16)" }
            } catch (e: Exception) {
                Log.e(TAG, "âŒ GPU ì‹¤íŒ¨ -> CPU ì „í™˜", e)
                options.setNumThreads(4)
                gpuDelegate = null
                runOnUiThread { binding.yoloxStatus.text = "ğŸ“¦ YOLOX: CPU" }
            }
            yoloxInterpreter = Interpreter(modelFile, options)
            val inputShape = yoloxInterpreter!!.getInputTensor(0).shape()
            val inputSize = if (inputShape.size >= 3 && inputShape[1] == 3) inputShape[2] else inputShape[1]
            Log.d(TAG, "YOLOX ë¡œë“œ | $modelFilename | ì…ë ¥ ${inputSize}x${inputSize}")
        } catch (e: Exception) {
            Log.e(TAG, "YOLOX ì´ˆê¸°í™” ì‹¤íŒ¨", e)
            runOnUiThread { binding.yoloxStatus.text = "Error: Init Failed" }
        }
    }

    private fun loadModelFile(modelName: String): MappedByteBuffer {
        val fileDescriptor = assets.openFd(modelName)
        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = inputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        val buffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
        return buffer
    }

    private fun startCamera() {
        val cameraProviderFuture = ProcessCameraProvider.getInstance(this)

        cameraProviderFuture.addListener({
            val cameraProvider = cameraProviderFuture.get()

            // Preview
            val preview = Preview.Builder()
                .build()
                .also {
                    it.setSurfaceProvider(binding.previewView.surfaceProvider)
                }

            // ImageAnalysis
            val imageAnalyzer = ImageAnalysis.Builder()
                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                .build()
                .also {
                    it.setAnalyzer(cameraExecutor, ImageAnalyzer())
                }

            // ì¹´ë©”ë¼ ì„ íƒ
            val cameraSelector = CameraSelector.DEFAULT_BACK_CAMERA

            try {
                cameraProvider.unbindAll()
                cameraProvider.bindToLifecycle(
                    this, cameraSelector, preview, imageAnalyzer
                )
            } catch (e: Exception) {
                Log.e(TAG, "ì¹´ë©”ë¼ ë°”ì¸ë”© ì‹¤íŒ¨", e)
            }

        }, ContextCompat.getMainExecutor(this))
    }

    // YOLOX ì§„ë‹¨ ë¡œê·¸: 3ì´ˆë§ˆë‹¤ í•œ ë²ˆë§Œ ì¶œë ¥ (ë¡œê·¸ ê³¼ë‹¤ ë°©ì§€)
    private var lastYoloxDiagTimeMs = 0L
    private var firstInferenceLogged = false
    private var lastTargetMatchDiagMs = 0L

    // ì´ë¯¸ì§€ ë¶„ì„ê¸°
    private inner class ImageAnalyzer : ImageAnalysis.Analyzer {

        override fun analyze(imageProxy: ImageProxy) {
            val startTime = System.currentTimeMillis()

            // Bitmap ë³€í™˜ (YUV_420_888 â†’ RGB)
            var bitmap = imageProxy.toBitmap()
            if (bitmap == null) {
                imageProxy.close()
                return
            }
            // ì„¸ë¡œ ëª¨ë“œì—ì„œ ì¹´ë©”ë¼ ì„¼ì„œëŠ” ë³´í†µ ê°€ë¡œ â†’ íšŒì „ ì •ë³´ ì ìš©í•´ ëª¨ë¸ ì…ë ¥ì´ í™”ë©´ê³¼ ë§ë„ë¡ í•¨
            val rotationDegrees = imageProxy.imageInfo.rotationDegrees
            if (rotationDegrees != 0) {
                bitmap = BitmapUtils.rotateBitmap(bitmap, rotationDegrees) ?: bitmap
            }

            val w = bitmap.width
            val h = bitmap.height
            val inferenceTime = System.currentTimeMillis() - startTime

            // MediaPipe Hands: LIVE_STREAM â†’ ë¹„ë™ê¸° ì „ë‹¬ë§Œ í•˜ê³  ì¦‰ì‹œ return (ë¸”ë¡œí‚¹ ì—†ìŒ)
            sendFrameToHands(bitmap, imageProxy.imageInfo.timestamp)

            when (searchState) {
                SearchState.SEARCHING -> {
                    val detections = runYOLOX(bitmap)
                    val matched = findTargetMatch(detections, getTargetLabel())
                    if (matched != null && matched.confidence >= TARGET_CONFIDENCE_THRESHOLD) {
                        // ê°™ì€ í´ë˜ìŠ¤ê°€ ì—°ì† ê°ì§€ëëŠ”ì§€ í™•ì¸ (ì˜ëª»ëœ í´ë˜ìŠ¤ ë°©ì§€)
                        val prev = pendingLockBox
                        if (prev != null && prev.label == matched.label &&
                            RectF.intersects(matched.rect, prev.rect)) {
                            pendingLockCount++
                            if (pendingLockCount >= LOCK_CONFIRM_FRAMES) {
                                pendingLockBox = null
                                pendingLockCount = 0
                                transitionToLocked(matched, w, h)
                                frozenBox = matched
                                frozenImageWidth = w
                                frozenImageHeight = h
                                wasOccluded = false
                                opticalFlowTracker.reset()
                                gyroManager.startTracking(matched.rect, w, h)
                                lockedFrameCount = 0
                                validationFailCount = 0
                                updateFPS()
                                imageProxy.close()
                                return
                            }
                        } else {
                            pendingLockBox = matched
                            pendingLockCount = 1
                        }
                    } else {
                        pendingLockBox = null
                        pendingLockCount = 0
                    }
                    displayResults(filterDetectionsByTarget(detections, getTargetLabel()), inferenceTime, w, h)
                }
                SearchState.LOCKED -> {
                    // YOLOX: Ní”„ë ˆì„ë§ˆë‹¤ ê²€ì¦ + ì‹œê° ë³´ì • (ìì´ë¡œ ë“œë¦¬í”„íŠ¸ ë³´ì •)
                    lockedFrameCount++
                    val shouldValidate = (lockedFrameCount % VALIDATION_INTERVAL) == 0
                    var inferMs = System.currentTimeMillis() - startTime

                    val handsOverlap = frozenBox?.let { box ->
                        isHandOverlappingBox(latestHandsResult.get(), box.rect, w, h)
                    } ?: false

                    gyroManager.suspendUpdates = handsOverlap

                    if (handsOverlap) {
                        // occlusion: optical flowë¡œ í™”ë©´ ì´ë™ëŸ‰ ì¶”ì  â†’ ë°•ìŠ¤ë„ ë™ì¼ ì´ë™
                        val handRect = mergedHandRect(latestHandsResult.get(), w, h)
                        val flow = opticalFlowTracker.update(bitmap, handRect, frozenBox?.rect)
                        flow?.let { (dx, dy) ->
                            val box = frozenBox ?: return@let
                            val r = box.rect
                            val newRect = RectF(r.left + dx, r.top + dy, r.right + dx, r.bottom + dy)
                            gyroManager.correctPosition(newRect)
                            frozenBox = box.copy(rect = newRect)
                        }
                    } else {
                        // occlusion í•´ì œ â†’ gyro ê¸°ì € ë™ê¸°í™”
                        if (wasOccluded) {
                            frozenBox?.rect?.let { gyroManager.correctPosition(it) }
                        }
                        if (shouldValidate) {
                            val detections = runYOLOX(bitmap)
                            inferMs = System.currentTimeMillis() - startTime
                            val minConf = TARGET_CONFIDENCE_THRESHOLD * 0.5f
                            val tracked = findTrackedTarget(detections, lockedTargetLabel, frozenBox, minConf)
                            if (tracked != null) {
                                validationFailCount = 0
                                gyroManager.correctPosition(tracked.rect)
                                frozenBox = tracked.copy(rotationDegrees = 0f)
                                frozenImageWidth = w
                                frozenImageHeight = h
                            } else {
                                validationFailCount++
                                if (validationFailCount >= VALIDATION_FAIL_LIMIT) {
                                    validationFailCount = 0
                                    gyroManager.resetToSearchingFromUI()
                                }
                            }
                        }
                    }
                    wasOccluded = handsOverlap

                    val box = frozenBox
                    val boxes = if (box != null) listOf(box) else emptyList()
                    displayResults(boxes, inferMs, frozenImageWidth, frozenImageHeight)
                }
            }

            updateFPS()
            imageProxy.close()
        }

        @androidx.camera.core.ExperimentalGetImage
        private fun ImageProxy.toBitmap(): Bitmap? {
            val image = this.image ?: return null
            // YUV_420_888 â†’ Bitmap ë³€í™˜ (ê°„ë‹¨ ë²„ì „)
            // ì‹¤ì œë¡œëŠ” ë” ìµœì í™”ëœ ë³€í™˜ í•„ìš”
            return BitmapUtils.yuv420ToBitmap(image)
        }
    }

    /** í™”ë©´ì´ ê±°ì˜ ì•ˆ ë³´ì¼ ì •ë„ë¡œ ì–´ë‘ìš°ë©´ true (ì†ìœ¼ë¡œ ê°€ë¦¼ ë“±) */
    private fun isImageTooDark(bitmap: Bitmap, threshold: Int = 35): Boolean {
        val w = bitmap.width
        val h = bitmap.height
        if (w == 0 || h == 0) return true
        val step = max(1, min(w, h) / 20)
        var sum = 0L
        var count = 0
        for (y in 0 until h step step) {
            for (x in 0 until w step step) {
                val p = bitmap.getPixel(x, y)
                sum += ((p shr 16) and 0xFF) + ((p shr 8) and 0xFF) + (p and 0xFF)
                count++
            }
        }
        if (count == 0) return true
        val avg = (sum / count) / 3
        return avg < threshold
    }

    private fun runYOLOX(bitmap: Bitmap): List<OverlayView.DetectionBox> {
        if (yoloxInterpreter == null) return emptyList()

        try {
            val inputShape = yoloxInterpreter!!.getInputTensor(0).shape()
            val isNchw = inputShape.size >= 4 && inputShape[1] == 3
            val inputSize = when {
                isNchw -> inputShape[2]
                inputShape.size >= 4 -> inputShape[1]
                else -> inputShape.last()
            }
            val expectedBytes = 4 * inputSize * inputSize * 3
            val preprocBitmap = Bitmap.createScaledBitmap(bitmap, inputSize, inputSize, true)
            val inputBuffer = bitmapToFloatBuffer(preprocBitmap, inputSize, isNchw)
            if (inputBuffer.remaining() != expectedBytes) {
                Log.e(TAG, "YOLOX ì…ë ¥ ë²„í¼ í¬ê¸° ë¶ˆì¼ì¹˜: ${inputBuffer.remaining()} != $expectedBytes")
                return emptyList()
            }
            val inferStart = System.currentTimeMillis()
            val outputShape = yoloxInterpreter!!.getOutputTensor(0).shape()
            val output = Array(outputShape[0]) { Array(outputShape[1]) { FloatArray(outputShape[2]) } }
            yoloxInterpreter!!.run(inputBuffer, output)
            val inferMs = System.currentTimeMillis() - inferStart
            if (isImageTooDark(bitmap)) {
                return emptyList()
            }
            val detections = parseYOLOXOutput(
                output[0],
                outputShape[1],
                outputShape[2],
                bitmap.width,
                bitmap.height,
                inputSize
            )
            if (!firstInferenceLogged) {
                firstInferenceLogged = true
                Log.d(TAG, "YOLOX ì²« ì¶”ë¡  | ì…ë ¥ bitmap ${bitmap.width}x${bitmap.height} â†’ resize ${inputSize}x${inputSize} | ì¶”ë¡  ${inferMs}ms")
            }
            val now = System.currentTimeMillis()
            if (now - lastYoloxDiagTimeMs >= 3000) {
                lastYoloxDiagTimeMs = now
                Log.d(TAG, "YOLOX ì§„ë‹¨ | ì¶”ë¡  ${inferMs}ms | ê°ì§€ ${detections.size}ê°œ maxConf=${String.format("%.2f", lastYoloxMaxConf)}")
            }
            return detections
        } catch (e: Exception) {
            Log.e(TAG, "YOLOX ì¶”ë¡  ì‹¤íŒ¨", e)
            return emptyList()
        }
    }

    private fun bitmapToByteBuffer(bitmap: Bitmap, size: Int): ByteBuffer {
        val buffer = ByteBuffer.allocateDirect(4 * size * size * 3)
        buffer.order(ByteOrder.nativeOrder())

        val pixels = IntArray(size * size)
        bitmap.getPixels(pixels, 0, size, 0, 0, size, size)

        for (pixelValue in pixels) {
            // [ìˆ˜ì •] FP16 ëª¨ë¸ì€ 0~255 ê°’ì„ 0.0~1.0ìœ¼ë¡œ 'ì •ê·œí™”' í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤!
            // ê¸°ì¡´ ì½”ë“œ: buffer.putFloat(...) -> í‹€ë¦¼
            // ìˆ˜ì • ì½”ë“œ: 255.0fë¡œ ë‚˜ëˆ„ê¸°

            buffer.putFloat(((pixelValue shr 16) and 0xFF) / 255.0f) // R
            buffer.putFloat(((pixelValue shr 8) and 0xFF) / 255.0f)  // G
            buffer.putFloat((pixelValue and 0xFF) / 255.0f)          // B
        }

        return buffer
    }

    private fun parseYOLOXOutput(
        output: Array<FloatArray>,
        dim1: Int,
        dim2: Int,
        imageWidth: Int,
        imageHeight: Int,
        inputSize: Int
    ): List<OverlayView.DetectionBox> {
        val numBoxes: Int
        val boxSize: Int
        val isRowMajor: Boolean

        if (dim1 >= dim2) {
            numBoxes = dim1
            boxSize = dim2
            isRowMajor = true
        } else {
            numBoxes = dim2
            boxSize = dim1
            isRowMajor = false
        }

        val isNormalized = if (isRowMajor && output.isNotEmpty() && output[0].size >= 4) {
            maxOf(output[0][0], output[0][1], output[0][2], output[0][3]) <= 1.5f
        } else if (!isRowMajor && output.size >= 4) {
            maxOf(output[0][0], output[1][0], output[2][0], output[3][0]) <= 1.5f
        } else true

        if (!yoloxShapeLogged) {
            yoloxShapeLogged = true
            Log.d(TAG, "YOLOX shape: dim1=$dim1 dim2=$dim2 â†’ numBoxes=$numBoxes boxSize=$boxSize")
        }

        val candidates = mutableListOf<OverlayView.DetectionBox>()
        // 4(box)+1(obj)+N(cls): 85(80), 58(53), 55(50), 54(49)
        val hasObjectness = (boxSize == 85 || boxSize == 58 || boxSize == 55 || boxSize == 54)
        val scoreStart = if (hasObjectness) 5 else 4
        val classCount = (boxSize - scoreStart).coerceAtLeast(1)

        val useSingleScoreFormat = (numBoxes <= 100 && boxSize >= 5)
        val minConfidenceToShow = when {
            useSingleScoreFormat -> 0.35f
            hasObjectness -> 0.45f
            else -> 0.78f
        }

        var maxConfidenceSeen = 0f

        for (j in 0 until numBoxes) {
            val v0: Float
            val v1: Float
            val v2: Float
            val v3: Float
            val classScores = FloatArray(classCount)
            var singleScore = 0f

            if (isRowMajor) {
                val row = output[j]
                if (row.size < boxSize) continue
                v0 = row[0]; v1 = row[1]; v2 = row[2]; v3 = row[3]
                if (row.size > 4) singleScore = row[4]
                for (c in 0 until classCount) classScores[c] = row[scoreStart + c]
            } else {
                v0 = output[0][j]; v1 = output[1][j]; v2 = output[2][j]; v3 = output[3][j]
                if (dim1 > 4) singleScore = output[4][j]
                for (c in 0 until classCount) classScores[c] = output[scoreStart + c][j]
            }

            val objScore = singleScore.coerceIn(0f, 1f)
            val topK = 3
            val topClassIds = classScores.indices
                .map { c ->
                    var rs = classScores[c]
                    if (rs > 1f || rs < 0f) rs = 1f / (1f + exp(-rs))
                    c to (objScore * rs).coerceIn(0f, 1f)
                }
                .sortedByDescending { it.second }
                .take(topK)
            val confidence = topClassIds.firstOrNull()?.second ?: 0f
            if (confidence > maxConfidenceSeen) maxConfidenceSeen = confidence
            if (confidence < minConfidenceToShow) continue

            // 50% ì´ìƒì¸ í´ë˜ìŠ¤ë§Œ í‘œì‹œ (ìƒìœ„ 3ê°œ ì¤‘ì—ì„œ)
            val topLabels = topClassIds
                .filter { (_, conf) -> conf >= 0.5f }
                .map { (cid, conf) ->
                    getClassLabel(cid) to (conf * 100).toInt()
                }

            // ì¢Œí‘œ: ì •ê·œí™” 0~1ì´ê³  v2>v0, v3>v1 ì´ë©´ (x1,y1,x2,y2). ì•„ë‹ˆë©´ (cx,cy,w,h).
            val left: Float
            val top: Float
            val right: Float
            val bottom: Float
            if (isNormalized && v2 > v0 && v3 > v1) {
                left = (v0 * imageWidth).coerceIn(0f, imageWidth.toFloat())
                top = (v1 * imageHeight).coerceIn(0f, imageHeight.toFloat())
                right = (v2 * imageWidth).coerceIn(0f, imageWidth.toFloat())
                bottom = (v3 * imageHeight).coerceIn(0f, imageHeight.toFloat())
            } else {
                if (isNormalized) {
                    val cx = v0.coerceIn(0f, 1f) * imageWidth
                    val cy = v1.coerceIn(0f, 1f) * imageHeight
                    val w = (v2.coerceIn(0f, 1f) * imageWidth) / 2f
                    val h = (v3.coerceIn(0f, 1f) * imageHeight) / 2f
                    left = max(0f, cx - w)
                    top = max(0f, cy - h)
                    right = min(imageWidth.toFloat(), cx + w)
                    bottom = min(imageHeight.toFloat(), cy + h)
                } else {
                    val cx = v0 / inputSize * imageWidth
                    val cy = v1 / inputSize * imageHeight
                    val w = (v2 / inputSize * imageWidth) / 2f
                    val h = (v3 / inputSize * imageHeight) / 2f
                    left = max(0f, cx - w)
                    top = max(0f, cy - h)
                    right = min(imageWidth.toFloat(), cx + w)
                    bottom = min(imageHeight.toFloat(), cy + h)
                }
            }

            if (right <= left || bottom <= top) continue

            candidates.add(
                OverlayView.DetectionBox(
                    label = topLabels.firstOrNull()?.first ?: "",
                    confidence = confidence,
                    rect = android.graphics.RectF(left, top, right, bottom),
                    topLabels = topLabels
                )
            )
        }

        lastYoloxMaxConf = maxConfidenceSeen
        return nms(candidates, iouThreshold = 0.6f)
    }

    private fun nms(boxes: List<OverlayView.DetectionBox>, iouThreshold: Float): List<OverlayView.DetectionBox> {
        val sorted = boxes.sortedByDescending { it.confidence }
        val picked = mutableListOf<OverlayView.DetectionBox>()
        val used = BooleanArray(sorted.size)

        for (i in sorted.indices) {
            if (used[i]) continue
            picked.add(sorted[i])
            for (j in i + 1 until sorted.size) {
                if (used[j]) continue
                if (iou(sorted[i].rect, sorted[j].rect) > iouThreshold) used[j] = true
            }
        }
        return picked
    }

    /** ì† ëœë“œë§ˆí¬(ì •ê·œí™” 0~1) â†’ ì´ë¯¸ì§€ ì¢Œí‘œ RectF */
    private fun handLandmarksToRect(landmarks: List<NormalizedLandmark>, imageWidth: Int, imageHeight: Int): RectF {
        if (landmarks.isEmpty()) return RectF(0f, 0f, 0f, 0f)
        val xs = landmarks.map { it.x().coerceIn(0f, 1f) * imageWidth }
        val ys = landmarks.map { it.y().coerceIn(0f, 1f) * imageHeight }
        return RectF(xs.min(), ys.min(), xs.max(), ys.max())
    }

    /** ì† ëœë“œë§ˆí¬ë“¤ â†’ ëª¨ë“  ì†ì„ í¬í•¨í•˜ëŠ” ë‹¨ì¼ RectF (optical flow ë§ˆìŠ¤í‚¹ìš©) */
    private fun mergedHandRect(handsResult: HandLandmarkerResult?, imageWidth: Int, imageHeight: Int): RectF? {
        val landmarks = handsResult?.landmarks() ?: return null
        if (landmarks.isEmpty()) return null
        var union: RectF? = null
        for (hand in landmarks) {
            val r = handLandmarksToRect(hand, imageWidth, imageHeight)
            union = if (union == null) r else {
                val u = RectF(union)
                u.union(r)
                u
            }
        }
        return union
    }

    /** ì†ì´ ë°•ìŠ¤ì™€ ê²¹ì¹˜ë©´ true (occlusion) */
    private fun isHandOverlappingBox(handsResult: HandLandmarkerResult?, boxRect: RectF, imageWidth: Int, imageHeight: Int): Boolean {
        val landmarks = handsResult?.landmarks() ?: return false
        if (imageWidth <= 0 || imageHeight <= 0) return false
        return landmarks.any { hand ->
            val handRect = handLandmarksToRect(hand, imageWidth, imageHeight)
            iou(handRect, boxRect) > 0.1f
        }
    }

    /** LIVE_STREAM: í”„ë ˆì„ë§Œ ë„˜ê¸°ê³  ì¦‰ì‹œ return. ê²°ê³¼ëŠ” resultListener ì½œë°±ìœ¼ë¡œ ì˜´. */
    private fun sendFrameToHands(bitmap: Bitmap, timestampNs: Long) {
        if (handLandmarker == null) return
        try {
            val mpImage = BitmapImageBuilder(bitmap).build()
            val timestampMs = timestampNs / 1_000_000
            handLandmarker!!.detectAsync(mpImage, timestampMs)
        } catch (e: Exception) {
            Log.e(TAG, "Hands detectAsync ì‹¤íŒ¨", e)
        }
    }

    private fun iou(a: android.graphics.RectF, b: android.graphics.RectF): Float {
        val interLeft = max(a.left, b.left)
        val interTop = max(a.top, b.top)
        val interRight = min(a.right, b.right)
        val interBottom = min(a.bottom, b.bottom)
        val interW = max(0f, interRight - interLeft)
        val interH = max(0f, interBottom - interTop)
        val interArea = interW * interH
        val areaA = a.width() * a.height()
        val areaB = b.width() * b.height()
        return interArea / (areaA + areaB - interArea + 1e-6f)
    }

    private fun displayResults(
        detections: List<OverlayView.DetectionBox>,
        inferenceTime: Long,
        imageWidth: Int,
        imageHeight: Int
    ) {
        runOnUiThread {
            binding.overlayView.setDetections(detections, imageWidth, imageHeight)
            binding.overlayView.setHands(latestHandsResult.get())

            when (searchState) {
                SearchState.SEARCHING -> {
                    binding.yoloxStatus.text = "ğŸ” íƒìƒ‰: ${getTargetLabel()} (${detections.size}ê°œ ê°ì§€)"
                    binding.handsStatus.text = "ğŸ“ ìì´ë¡œ: OFF"
                }
                SearchState.LOCKED -> {
                    val box = frozenBox
                    if (box != null) {
                        binding.yoloxStatus.text = "ğŸ”’ ê³ ì •: ${box.label} (ìì´ë¡œ)"
                    }
                    binding.handsStatus.text = "ğŸ“ ìì´ë¡œ: ON"
                }
            }

            binding.inferenceTime.text = "â±ï¸ Inference: ${inferenceTime}ms"
        }
    }

    private fun updateFPS() {
        frameCount++
        val currentTime = System.currentTimeMillis()
        if (currentTime - lastFpsTime >= 1000) {
            val fps = frameCount * 1000 / (currentTime - lastFpsTime)
            runOnUiThread {
                binding.fpsText.text = "FPS: $fps"
            }
            frameCount = 0
            lastFpsTime = currentTime
        }
    }

    private fun allPermissionsGranted() = REQUIRED_PERMISSIONS.all {
        ContextCompat.checkSelfPermission(baseContext, it) == PackageManager.PERMISSION_GRANTED
    }

    override fun onRequestPermissionsResult(
        requestCode: Int,
        permissions: Array<out String>,
        grantResults: IntArray
    ) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQUEST_CODE_PERMISSIONS) {
            if (allPermissionsGranted()) {
                binding.startSearchBtn.visibility = View.VISIBLE
            } else {
                Toast.makeText(this, "ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
                finish()
            }
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        cameraExecutor.shutdown()
        yoloxInterpreter?.close()
        gpuDelegate?.close()
        handLandmarker?.close()
        if (::gyroManager.isInitialized) gyroManager.stopTracking()
    }

    companion object {
        private const val TAG = "GrabIT_Test"
        private var yoloxShapeLogged = false
    }
}